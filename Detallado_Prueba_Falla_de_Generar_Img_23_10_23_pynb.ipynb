{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0qsI6tXMc+R8+zHPzr/00",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizzz9/patrones/blob/master/Detallado_Prueba_Falla_de_Generar_Img_23_10_23_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Sección nueva"
      ],
      "metadata": {
        "id": "AiNtYKzG2vVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \taiohttp==3.8.6\n",
        "!pip install \tBabel==2.13.0\n",
        "!pip install \tbigframes==0.10.0\n",
        "!pip install \tbokeh==3.2.2\n",
        "!pip install \tbranca==0.6.0\n",
        "!pip install \tcachetools==5.3.1\n",
        "!pip install \tcertifi==2023.7.22\n",
        "!pip install \tcharset-normalizer==3.3.0\n",
        "!pip install \tcmake==3.27.7\n",
        "!pip install \tconfection==0.1.3\n",
        "!pip install \tcontourpy==1.1.1\n",
        "!pip install \tcryptography==41.0.4\n",
        "!pip install \tCython==3.0.4\n",
        "!pip install \tduckdb==0.8.1\n",
        "!pip install \tearthengine-api==0.1.375\n",
        "!pip install \teasydict==1.10\n",
        "!pip install \tetils==1.5.1\n",
        "!pip install \texceptiongroup==1.1.3\n",
        "!pip install \tfastjsonschema==2.18.1\n",
        "!pip install \tfilelock==3.12.4\n",
        "!pip install \tflax==0.7.4\n",
        "!pip install \tfonttools==4.43.1\n",
        "!pip install \tfrozendict==2.3.8\n",
        "!pip install \tgeemap==0.28.2\n",
        "!pip install \tgoogle-cloud-bigquery-storage==2.22.0\n",
        "!pip install \t1.0.0.tar.gz#sha256=c5a2da9a372b66a92fd9c3331efca7e591a029ca013967a39a7a18ff1d2fef5d\n",
        "!pip install \tgreenlet==3.0.0\n",
        "!pip install \tgrpc-google-iam-v1==0.12.6\n",
        "!pip install \tgrpcio==1.59.0\n",
        "!pip install \th5netcdf==1.2.0\n",
        "!pip install \tholidays==0.35\n",
        "!pip install \tidna==3.4\n",
        "!pip install \timageio==2.31.5\n",
        "!pip install \timportlib-metadata==6.8.0\n",
        "!pip install \timportlib-resources==6.1.0\n",
        "!pip install \tipyleaflet==0.17.4\n",
        "\n",
        "!pip install \tjsonschema==4.19.1\n",
        "!pip install \tjsonschema-specifications==2023.7.1\n",
        "!pip install \tjupyter_core==5.4.0\n",
        "!pip install \tjupyterlab-pygments==0.2.2\n",
        "!pip install \tlightgbm==4.0.0\n",
        "!pip install \tllvmlite==0.39.1\n",
        "!pip install \tmalloy==2023.1058\n",
        "!pip install \tMarkdown==3.5\n",
        "!pip install \tnbclient==0.8.0\n",
        "!pip install \tnetworkx==3.2\n",
        "!pip install \tnumba==0.56.4\n",
        "!pip install \torbax-checkpoint==0.4.1\n",
        "!pip install \tpandas-gbq==0.17.9\n",
        "!pip install \tpanel==1.2.3\n",
        "!pip install \tparam==1.13.0\n",
        "!pip install \tpatsy==0.5.3\n",
        "!pip install \tpexpect==4.8.0\n",
        "!pip install \tplatformdirs==3.11.0\n",
        "!pip install \tplotnine==0.12.3\n",
        "!pip install \tpooch==1.7.0\n",
        "!pip install \tprometheus-client==0.17.1\n",
        "!pip install \tpromise==2.3\n",
        "!pip install \tprompt-toolkit==3.0.39\n",
        "!pip install \tpyarrow==9.0.0\n",
        "!pip install \tpyasn1==0.5.0\n",
        "!pip install \tpyOpenSSL==23.2.0\n",
        "!pip install \tpytest==7.4.2\n",
        "!pip install \tPyWavelets==1.4.1\n",
        "!pip install \treferencing==0.30.2\n",
        "!pip install \trich==13.6.0\n",
        "!pip install \trpds-py==0.10.6\n",
        "!pip install \tscipy==1.11.3\n",
        "!pip install \tscooby==0.8.0\n",
        "!pip install \tscs==3.2.3\n",
        "!pip install \tSQLAlchemy==2.0.22\n",
        "!pip install \ttbb==2021.10.0\n",
        "!pip install \ttblib==2.0.0\n",
        "!pip install \ttensorboard-data-server==0.7.1\n",
        "!pip install \tterminado==0.17.1\n",
        "!pip install \ttermcolor==2.3.0\n",
        "!pip install \ttweepy==4.13.0\n",
        "!pip install \ttypes-setuptools==68.2.0.0\n",
        "!pip install \ttzlocal==5.1\n",
        "!pip install \twcwidth==0.2.8\n",
        "!pip install \twebsocket-client==1.6.4\n",
        "!pip install \tWerkzeug==3.0.0\n",
        "!pip install \txgboost==2.0.0\n",
        "!pip install \txyzservices==2023.10.0\n",
        "!pip install \tyarl==1.9.2\n",
        "!pip install \tyfinance==0.2.31\n",
        "!pip install \tzipp==3.17.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JU8dPk9nfyG",
        "outputId": "b9c34eaf-72d3-4448-d559-eeb660e95a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aiohttp==3.8.6\n",
            "  Downloading aiohttp-3.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.6) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.6) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.6) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.6) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.6) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.6) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.6) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.8.6) (3.6)\n",
            "Installing collected packages: aiohttp\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.9.1\n",
            "    Uninstalling aiohttp-3.9.1:\n",
            "      Successfully uninstalled aiohttp-3.9.1\n",
            "Successfully installed aiohttp-3.8.6\n",
            "Collecting Babel==2.13.0\n",
            "  Downloading Babel-2.13.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Babel\n",
            "  Attempting uninstall: Babel\n",
            "    Found existing installation: Babel 2.13.1\n",
            "    Uninstalling Babel-2.13.1:\n",
            "      Successfully uninstalled Babel-2.13.1\n",
            "Successfully installed Babel-2.13.0\n",
            "Collecting bigframes==0.10.0\n",
            "  Downloading bigframes-0.10.0-py2.py3-none-any.whl (351 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m351.1/351.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2023.3.0 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (2023.6.0)\n",
            "Requirement already satisfied: gcsfs>=2023.3.0 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (2023.6.0)\n",
            "Requirement already satisfied: geopandas>=0.12.2 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (0.13.2)\n",
            "Requirement already satisfied: google-auth<3.0dev,>2.14.1 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (2.17.3)\n",
            "Requirement already satisfied: google-cloud-bigquery[bqstorage,pandas]>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (3.12.0)\n",
            "Requirement already satisfied: google-cloud-functions>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (1.13.3)\n",
            "Requirement already satisfied: google-cloud-bigquery-connection>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (1.12.1)\n",
            "Requirement already satisfied: google-cloud-iam>=2.12.1 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (2.12.2)\n",
            "Requirement already satisfied: google-cloud-resource-manager>=1.10.3 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (1.10.4)\n",
            "Requirement already satisfied: google-cloud-storage>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (2.8.0)\n",
            "Requirement already satisfied: ibis-framework[bigquery]<7.0.0dev,>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (6.2.0)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (1.5.3)\n",
            "Requirement already satisfied: pydata-google-auth>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (1.8.2)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (1.2.2)\n",
            "Requirement already satisfied: sqlalchemy<3.0dev,>=1.4 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (2.0.23)\n",
            "Requirement already satisfied: ipywidgets>=7.7.1 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (7.7.1)\n",
            "Requirement already satisfied: humanize>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from bigframes==0.10.0) (4.7.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2023.3.0->bigframes==0.10.0) (3.8.6)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2023.3.0->bigframes==0.10.0) (4.4.2)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2023.3.0->bigframes==0.10.0) (1.0.0)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.12.2->bigframes==0.10.0) (1.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.12.2->bigframes==0.10.0) (23.2)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.12.2->bigframes==0.10.0) (3.6.1)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.12.2->bigframes==0.10.0) (2.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>2.14.1->bigframes==0.10.0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>2.14.1->bigframes==0.10.0) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>2.14.1->bigframes==0.10.0) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>2.14.1->bigframes==0.10.0) (4.9)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery-connection>=1.12.0->bigframes==0.10.0) (2.11.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery-connection>=1.12.0->bigframes==0.10.0) (1.22.3)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery-connection>=1.12.0->bigframes==0.10.0) (3.20.3)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery-connection>=1.12.0->bigframes==0.10.0) (0.12.7)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes==0.10.0) (1.59.3)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes==0.10.0) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes==0.10.0) (2.6.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes==0.10.0) (2.8.2)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3.0.0dev,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: pyarrow>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes==0.10.0) (10.0.1)\n",
            "Requirement already satisfied: db-dtypes<2.0.0dev,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes==0.10.0) (1.1.1)\n",
            "Requirement already satisfied: atpublic<5,>=2.3 in /usr/local/lib/python3.10/dist-packages (from ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (4.0)\n",
            "Requirement already satisfied: bidict<1,>=0.22.1 in /usr/local/lib/python3.10/dist-packages (from ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (0.22.1)\n",
            "Requirement already satisfied: filelock<4,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (3.13.1)\n",
            "Requirement already satisfied: multipledispatch<2,>=0.6 in /usr/local/lib/python3.10/dist-packages (from ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (1.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (1.23.5)\n",
            "Requirement already satisfied: parsy<3,>=2 in /usr/local/lib/python3.10/dist-packages (from ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (2.1)\n",
            "Requirement already satisfied: pooch[progress,xxhash]<2,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (1.8.0)\n",
            "Requirement already satisfied: pytz>=2022.7 in /usr/local/lib/python3.10/dist-packages (from ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (2023.3.post1)\n",
            "Requirement already satisfied: rich<14,>=12.4.4 in /usr/local/lib/python3.10/dist-packages (from ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (13.7.0)\n",
            "Requirement already satisfied: sqlglot<18,>=10.4.3 in /usr/local/lib/python3.10/dist-packages (from ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (17.16.2)\n",
            "Requirement already satisfied: toolz<1,>=0.11 in /usr/local/lib/python3.10/dist-packages (from ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (4.5.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.7.1->bigframes==0.10.0) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.7.1->bigframes==0.10.0) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.7.1->bigframes==0.10.0) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.7.1->bigframes==0.10.0) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.7.1->bigframes==0.10.0) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.7.1->bigframes==0.10.0) (3.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pydata-google-auth>=1.8.2->bigframes==0.10.0) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->bigframes==0.10.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->bigframes==0.10.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->bigframes==0.10.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->bigframes==0.10.0) (2023.11.17)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->bigframes==0.10.0) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->bigframes==0.10.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->bigframes==0.10.0) (3.2.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3.0dev,>=1.4->bigframes==0.10.0) (3.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes==0.10.0) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes==0.10.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes==0.10.0) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes==0.10.0) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes==0.10.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2023.3.0->bigframes==0.10.0) (1.3.1)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.12.2->bigframes==0.10.0) (8.1.7)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.12.2->bigframes==0.10.0) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.12.2->bigframes==0.10.0) (0.7.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-bigquery-connection>=1.12.0->bigframes==0.10.0) (1.61.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-bigquery-connection>=1.12.0->bigframes==0.10.0) (1.48.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib->gcsfs>=2023.3.0->bigframes==0.10.0) (1.3.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery[bqstorage,pandas]>=3.10.0->bigframes==0.10.0) (1.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.7.1->bigframes==0.10.0) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.7.1->bigframes==0.10.0) (6.3.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets>=7.7.1->bigframes==0.10.0)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.7.1->bigframes==0.10.0) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.7.1->bigframes==0.10.0) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.7.1->bigframes==0.10.0) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch[progress,xxhash]<2,>=1.6.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (4.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from pooch[progress,xxhash]<2,>=1.6.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (4.66.1)\n",
            "Requirement already satisfied: xxhash>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from pooch[progress,xxhash]<2,>=1.6.0->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>2.14.1->bigframes==0.10.0) (0.5.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=12.4.4->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (3.0.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.8.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=12.4.4->ibis-framework[bigquery]<7.0.0dev,>=6.2.0->bigframes==0.10.0) (0.1.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (3.1.2)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (5.5.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (1.5.8)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (1.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.2.12)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs>=2023.3.0->bigframes==0.10.0) (3.2.2)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (4.19.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (21.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.13.2)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (0.5.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.7.1->bigframes==0.10.0) (2.21)\n",
            "Installing collected packages: jedi, bigframes\n",
            "  Attempting uninstall: bigframes\n",
            "    Found existing installation: bigframes 0.15.0\n",
            "    Uninstalling bigframes-0.15.0:\n",
            "      Successfully uninstalled bigframes-0.15.0\n",
            "Successfully installed bigframes-0.10.0 jedi-0.19.1\n",
            "Collecting bokeh==3.2.2\n",
            "  Downloading bokeh-3.2.2-py3-none-any.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.2.2) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.2.2) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.2.2) (1.23.5)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.2.2) (23.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.2.2) (1.5.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.2.2) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.2.2) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.2.2) (6.3.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.2.2) (2023.10.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh==3.2.2) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh==3.2.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh==3.2.2) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.2->bokeh==3.2.2) (1.16.0)\n",
            "Installing collected packages: bokeh\n",
            "  Attempting uninstall: bokeh\n",
            "    Found existing installation: bokeh 3.3.2\n",
            "    Uninstalling bokeh-3.3.2:\n",
            "      Successfully uninstalled bokeh-3.3.2\n",
            "Successfully installed bokeh-3.2.2\n",
            "Collecting branca==0.6.0\n",
            "  Downloading branca-0.6.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from branca==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->branca==0.6.0) (2.1.3)\n",
            "Installing collected packages: branca\n",
            "  Attempting uninstall: branca\n",
            "    Found existing installation: branca 0.7.0\n",
            "    Uninstalling branca-0.7.0:\n",
            "      Successfully uninstalled branca-0.7.0\n",
            "Successfully installed branca-0.6.0\n",
            "Collecting cachetools==5.3.1\n",
            "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
            "Installing collected packages: cachetools\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.3.2\n",
            "    Uninstalling cachetools-5.3.2:\n",
            "      Successfully uninstalled cachetools-5.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cachetools-5.3.1\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting charset-normalizer==3.3.0\n",
            "  Downloading charset_normalizer-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: charset-normalizer\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n",
            "Successfully installed charset-normalizer-3.3.0\n",
            "Collecting cmake==3.27.7\n",
            "  Downloading cmake-3.27.7-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting confection==0.1.3\n",
            "  Downloading confection-0.1.3-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from confection==0.1.3) (1.10.13)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from confection==0.1.3) (2.4.8)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->confection==0.1.3) (4.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from srsly<3.0.0,>=2.4.0->confection==0.1.3) (2.0.10)\n",
            "Installing collected packages: confection\n",
            "  Attempting uninstall: confection\n",
            "    Found existing installation: confection 0.1.4\n",
            "    Uninstalling confection-0.1.4:\n",
            "      Successfully uninstalled confection-0.1.4\n",
            "Successfully installed confection-0.1.3\n",
            "Collecting contourpy==1.1.1\n",
            "  Downloading contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.7/301.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16 in /usr/local/lib/python3.10/dist-packages (from contourpy==1.1.1) (1.23.5)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3173, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4959, in parseImpl\n",
            "    loc, tokens = self_expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 5226, in parseImpl\n",
            "    return super().parseImpl(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 862, in _parseNoCache\n",
            "    ret_tokens = ParseResults(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/results.py\", line 139, in __new__\n",
            "    self = object.__new__(cls)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 172, in emit\n",
            "    style = Style(color=\"red\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/style.py\", line 146, in __init__\n",
            "    def _make_color(color: Union[Color, str]) -> Color:\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 309, in inner\n",
            "    return cached(*args, **kwds)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 403, in __getitem__\n",
            "    return self._getitem(self, parameters)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 515, in Union\n",
            "    parameters = tuple(_type_check(p, msg) for p in parameters)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 515, in <genexpr>\n",
            "    parameters = tuple(_type_check(p, msg) for p in parameters)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 168, in _type_check\n",
            "    if arg in (Any, NoReturn, Final, TypeAlias):\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Collecting cryptography==41.0.4\n",
            "  Downloading cryptography-41.0.4-cp37-abi3-manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography==41.0.4) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography==41.0.4) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Envejecimiento Facial"
      ],
      "metadata": {
        "id": "EkYdT82bWo8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conexión a drive para acceder a las imagenes de prueba"
      ],
      "metadata": {
        "id": "bPpI0zxfV4db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbhYmp4eKfAT",
        "outputId": "122e63cc-dd6c-4b67-e557-bc017ed9ccc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imageio import imsave"
      ],
      "metadata": {
        "id": "uGWxoerv7LFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio"
      ],
      "metadata": {
        "id": "OVYzGx0p7MeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Versiones de librerias"
      ],
      "metadata": {
        "id": "ooZrwzK_OIfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip  freeze"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emNAZwOCfcO2",
        "outputId": "db06d09a-ffd6-43d2-9ffe-0ca0dc68d517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "aiohttp==3.8.6\n",
            "aiosignal==1.3.1\n",
            "alabaster==0.7.13\n",
            "albumentations==1.3.1\n",
            "altair==4.2.2\n",
            "anyio==3.7.1\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==23.1.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array-record==0.5.0\n",
            "arviz==0.15.1\n",
            "astropy==5.3.4\n",
            "astunparse==1.6.3\n",
            "async-timeout==4.0.3\n",
            "atpublic==4.0\n",
            "attrs==23.1.0\n",
            "audioread==3.0.1\n",
            "autograd==1.6.2\n",
            "Babel==2.13.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.11.2\n",
            "bidict==0.22.1\n",
            "bigframes==0.10.0\n",
            "bleach==6.1.0\n",
            "blinker==1.4\n",
            "blis==0.7.11\n",
            "blosc2==2.0.0\n",
            "bokeh==3.2.2\n",
            "bqplot==0.12.42\n",
            "branca==0.6.0\n",
            "build==1.0.3\n",
            "CacheControl==0.13.1\n",
            "cachetools==5.3.1\n",
            "catalogue==2.0.10\n",
            "certifi==2023.11.17\n",
            "cffi==1.16.0\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.3.0\n",
            "chex==0.1.7\n",
            "click==8.1.7\n",
            "click-plugins==1.1.1\n",
            "cligj==0.7.2\n",
            "cloudpickle==2.2.1\n",
            "cmake==3.27.9\n",
            "cmdstanpy==1.2.0\n",
            "colorcet==3.0.1\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.3\n",
            "cons==0.4.6\n",
            "contextlib2==21.6.0\n",
            "contourpy==1.2.0\n",
            "cryptography==41.0.4\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda11x==11.0.0\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.3.2\n",
            "cycler==0.12.1\n",
            "cymem==2.0.8\n",
            "Cython==3.0.6\n",
            "dask==2023.8.1\n",
            "datascience==0.17.6\n",
            "db-dtypes==1.1.1\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.6.6\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "diskcache==5.6.3\n",
            "distributed==2023.8.1\n",
            "distro==1.7.0\n",
            "dlib==19.24.2\n",
            "dm-tree==0.1.8\n",
            "docutils==0.18.1\n",
            "dopamine-rl==4.0.6\n",
            "duckdb==0.9.2\n",
            "earthengine-api==0.1.381\n",
            "easydict==1.11\n",
            "ecos==2.0.12\n",
            "editdistance==0.6.2\n",
            "eerepr==0.0.4\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl#sha256=83276fc78a70045627144786b52e1f2728ad5e29e5e43916ec37ea9c26a11212\n",
            "entrypoints==0.4\n",
            "et-xmlfile==1.1.0\n",
            "etils==1.5.2\n",
            "etuples==0.3.9\n",
            "exceptiongroup==1.2.0\n",
            "fastai==2.7.13\n",
            "fastcore==1.5.29\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.19.0\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.2\n",
            "filelock==3.13.1\n",
            "fiona==1.9.5\n",
            "firebase-admin==5.3.0\n",
            "Flask==2.2.5\n",
            "flatbuffers==23.5.26\n",
            "flax==0.7.5\n",
            "folium==0.14.0\n",
            "fonttools==4.46.0\n",
            "frozendict==2.3.10\n",
            "frozenlist==1.4.0\n",
            "fsspec==2023.6.0\n",
            "future==0.18.3\n",
            "gast==0.5.4\n",
            "gcsfs==2023.6.0\n",
            "GDAL==3.4.3\n",
            "gdown==4.6.6\n",
            "geemap==0.29.6\n",
            "gensim==4.3.2\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==0.13.2\n",
            "geopy==2.3.0\n",
            "gin-config==0.5.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-ai-generativelanguage==0.3.3\n",
            "google-api-core==2.11.1\n",
            "google-api-python-client==2.84.0\n",
            "google-auth==2.17.3\n",
            "google-auth-httplib2==0.1.1\n",
            "google-auth-oauthlib==1.0.0\n",
            "google-cloud-aiplatform==1.36.4\n",
            "google-cloud-bigquery==3.12.0\n",
            "google-cloud-bigquery-connection==1.12.1\n",
            "google-cloud-bigquery-storage==2.23.0\n",
            "google-cloud-core==2.3.3\n",
            "google-cloud-datastore==2.15.2\n",
            "google-cloud-firestore==2.11.1\n",
            "google-cloud-functions==1.13.3\n",
            "google-cloud-iam==2.12.2\n",
            "google-cloud-language==2.9.1\n",
            "google-cloud-resource-manager==1.10.4\n",
            "google-cloud-storage==2.8.0\n",
            "google-cloud-translate==3.11.3\n",
            "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=71ffdc197221532fe880d94844bc08f8c50de90104d8ad3d3a9313f5e5a185e9\n",
            "google-crc32c==1.5.0\n",
            "google-generativeai==0.2.2\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.6.0\n",
            "googleapis-common-protos==1.61.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.20.1\n",
            "greenlet==3.0.1\n",
            "grpc-google-iam-v1==0.12.7\n",
            "grpcio==1.59.3\n",
            "grpcio-status==1.48.2\n",
            "gspread==3.4.2\n",
            "gspread-dataframe==3.3.1\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h5netcdf==1.3.0\n",
            "h5py==3.9.0\n",
            "holidays==0.38\n",
            "holoviews==1.17.1\n",
            "html5lib==1.1\n",
            "httpimport==1.3.1\n",
            "httplib2==0.22.0\n",
            "huggingface-hub==0.19.4\n",
            "humanize==4.7.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==6.2.0\n",
            "idna==3.6\n",
            "imageio==2.31.6\n",
            "imageio-ffmpeg==0.4.9\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.10.1\n",
            "imgaug==0.4.0\n",
            "importlib-metadata==7.0.0\n",
            "importlib-resources==6.1.1\n",
            "imutils==0.5.4\n",
            "inflect==7.0.0\n",
            "iniconfig==2.0.0\n",
            "install==1.3.5\n",
            "intel-openmp==2023.2.0\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==5.5.6\n",
            "ipyleaflet==0.18.0\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.1.2\n",
            "jax==0.4.20\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.20+cuda11.cudnn86-cp310-cp310-manylinux2014_x86_64.whl#sha256=01be66238133f884bf5adf15cd7eaaf8445f9d4b056c5c64df28a997a6aff2fe\n",
            "jedi==0.19.1\n",
            "jeepney==0.7.1\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.2\n",
            "joblib==1.3.2\n",
            "jsonpickle==3.0.2\n",
            "jsonschema==4.19.2\n",
            "jsonschema-specifications==2023.11.2\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.5.0\n",
            "jupyterlab-widgets==3.0.9\n",
            "jupyterlab_pygments==0.3.0\n",
            "kaggle==1.5.16\n",
            "keras==2.14.0\n",
            "keyring==23.5.0\n",
            "kiwisolver==1.4.5\n",
            "langcodes==3.3.0\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.3\n",
            "libclang==16.0.6\n",
            "librosa==0.10.1\n",
            "lida==0.0.10\n",
            "lightgbm==4.1.0\n",
            "linkify-it-py==2.0.2\n",
            "llmx==0.0.15a0\n",
            "llvmlite==0.41.1\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==4.9.3\n",
            "malloy==2023.1067\n",
            "Markdown==3.5.1\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==2.1.3\n",
            "matplotlib==3.7.1\n",
            "matplotlib-inline==0.1.6\n",
            "matplotlib-venn==0.11.9\n",
            "mdit-py-plugins==0.4.0\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==0.8.4\n",
            "mizani==0.9.3\n",
            "mkl==2023.2.0\n",
            "ml-dtypes==0.2.0\n",
            "mlxtend==0.22.0\n",
            "more-itertools==10.1.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.0.7\n",
            "multidict==6.0.4\n",
            "multipledispatch==1.0.0\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.10\n",
            "music21==9.1.0\n",
            "natsort==8.4.0\n",
            "nbclassic==1.0.0\n",
            "nbclient==0.9.0\n",
            "nbconvert==6.5.4\n",
            "nbformat==5.9.2\n",
            "nest-asyncio==1.5.8\n",
            "networkx==3.2.1\n",
            "nibabel==4.0.2\n",
            "nltk==3.8.1\n",
            "notebook==6.5.5\n",
            "notebook_shim==0.2.3\n",
            "numba==0.58.1\n",
            "numexpr==2.8.7\n",
            "numpy==1.23.5\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "opencv-contrib-python==4.8.0.76\n",
            "opencv-python==4.8.0.76\n",
            "opencv-python-headless==4.8.1.78\n",
            "openpyxl==3.1.2\n",
            "opt-einsum==3.3.0\n",
            "optax==0.1.7\n",
            "orbax-checkpoint==0.4.4\n",
            "osqp==0.6.2.post8\n",
            "packaging==23.2\n",
            "pandas==1.5.3\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.19.2\n",
            "pandas-stubs==1.5.3.230304\n",
            "pandocfilters==1.5.0\n",
            "panel==1.3.4\n",
            "param==2.0.1\n",
            "parso==0.8.3\n",
            "parsy==2.1\n",
            "partd==1.4.1\n",
            "pathlib==1.0.1\n",
            "pathy==0.10.3\n",
            "patsy==0.5.4\n",
            "peewee==3.17.0\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==9.4.0\n",
            "pip-tools==6.13.0\n",
            "platformdirs==4.1.0\n",
            "plotly==5.15.0\n",
            "plotnine==0.12.4\n",
            "pluggy==1.3.0\n",
            "polars==0.17.3\n",
            "pooch==1.8.0\n",
            "portpicker==1.5.2\n",
            "prefetch-generator==1.0.3\n",
            "preshed==3.0.9\n",
            "prettytable==3.9.0\n",
            "proglog==0.1.10\n",
            "progressbar2==4.2.0\n",
            "prometheus-client==0.19.0\n",
            "promise==2.3\n",
            "prompt-toolkit==3.0.41\n",
            "prophet==1.1.5\n",
            "proto-plus==1.22.3\n",
            "protobuf==3.20.3\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.9\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==10.0.1\n",
            "pyasn1==0.5.1\n",
            "pyasn1-modules==0.3.0\n",
            "pycocotools==2.0.7\n",
            "pycparser==2.21\n",
            "pyct==0.5.0\n",
            "pydantic==1.10.13\n",
            "pydata-google-auth==1.8.2\n",
            "pydot==1.4.2\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "PyDrive2==1.6.3\n",
            "pyerfa==2.0.1.1\n",
            "pygame==2.5.2\n",
            "Pygments==2.16.1\n",
            "PyGObject==3.42.1\n",
            "PyJWT==2.3.0\n",
            "pymc==5.7.2\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.7\n",
            "pyOpenSSL==23.3.0\n",
            "pyparsing==3.1.1\n",
            "pyperclip==1.8.2\n",
            "pyproj==3.6.1\n",
            "pyproject_hooks==1.0.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pytensor==2.14.2\n",
            "pytest==7.4.3\n",
            "python-apt==0.0.0\n",
            "python-box==7.1.1\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.1\n",
            "python-utils==3.8.1\n",
            "pytz==2023.3.post1\n",
            "pyviz_comms==3.0.0\n",
            "PyWavelets==1.5.0\n",
            "PyYAML==6.0.1\n",
            "pyzmq==23.2.1\n",
            "qdldl==0.1.7.post0\n",
            "qudida==0.0.4\n",
            "ratelim==0.1.6\n",
            "referencing==0.31.1\n",
            "regex==2023.6.3\n",
            "requests==2.31.0\n",
            "requests-oauthlib==1.3.1\n",
            "requirements-parser==0.5.0\n",
            "rich==13.7.0\n",
            "rpds-py==0.13.2\n",
            "rpy2==3.4.2\n",
            "rsa==4.9\n",
            "safetensors==0.4.1\n",
            "scikit-image==0.19.3\n",
            "scikit-learn==1.2.2\n",
            "scipy==1.11.3\n",
            "scooby==0.9.2\n",
            "scs==3.2.4.post1\n",
            "seaborn==0.12.2\n",
            "SecretStorage==3.3.1\n",
            "Send2Trash==1.8.2\n",
            "shapely==2.0.2\n",
            "six==1.16.0\n",
            "sklearn-pandas==2.2.0\n",
            "smart-open==6.4.0\n",
            "sniffio==1.3.0\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.12.1\n",
            "soupsieve==2.5\n",
            "soxr==0.3.7\n",
            "spacy==3.6.1\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "Sphinx==5.0.2\n",
            "sphinxcontrib-applehelp==1.0.7\n",
            "sphinxcontrib-devhelp==1.0.5\n",
            "sphinxcontrib-htmlhelp==2.0.4\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==1.0.6\n",
            "sphinxcontrib-serializinghtml==1.1.9\n",
            "SQLAlchemy==2.0.23\n",
            "sqlglot==17.16.2\n",
            "sqlparse==0.4.4\n",
            "srsly==2.4.8\n",
            "stanio==0.3.0\n",
            "statsmodels==0.14.0\n",
            "sympy==1.12\n",
            "tables==3.8.0\n",
            "tabulate==0.9.0\n",
            "tbb==2021.11.0\n",
            "tblib==3.0.0\n",
            "tenacity==8.2.3\n",
            "tensorboard==2.14.1\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.14.0\n",
            "tensorflow-datasets==4.9.3\n",
            "tensorflow-estimator==2.14.0\n",
            "tensorflow-gcs-config==2.14.0\n",
            "tensorflow-hub==0.15.0\n",
            "tensorflow-io-gcs-filesystem==0.34.0\n",
            "tensorflow-metadata==1.14.0\n",
            "tensorflow-probability==0.22.0\n",
            "tensorstore==0.1.45\n",
            "termcolor==2.4.0\n",
            "terminado==0.18.0\n",
            "text-unidecode==1.3\n",
            "textblob==0.17.1\n",
            "tf-slim==1.1.0\n",
            "thinc==8.1.12\n",
            "threadpoolctl==3.2.0\n",
            "tifffile==2023.9.26\n",
            "tinycss2==1.2.1\n",
            "tokenizers==0.15.0\n",
            "toml==0.10.2\n",
            "tomli==2.0.1\n",
            "toolz==0.12.0\n",
            "torch @ https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=a81b554184492005543ddc32e96469f9369d778dedd195d73bda9bed407d6589\n",
            "torchaudio @ https://download.pytorch.org/whl/cu118/torchaudio-2.1.0%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=cdfd0a129406155eee595f408cafbb92589652da4090d1d2040f5453d4cae71f\n",
            "torchdata==0.7.0\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.16.0\n",
            "torchvision @ https://download.pytorch.org/whl/cu118/torchvision-0.16.0%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=033712f65d45afe806676c4129dfe601ad1321d9e092df62b15847c02d4061dc\n",
            "tornado==6.3.2\n",
            "tqdm==4.66.1\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers==4.35.2\n",
            "triton==2.1.0\n",
            "tweepy==4.14.0\n",
            "typer==0.9.0\n",
            "types-pytz==2023.3.1.1\n",
            "types-setuptools==69.0.0.0\n",
            "typing_extensions==4.5.0\n",
            "tzlocal==5.2\n",
            "uc-micro-py==1.0.2\n",
            "uritemplate==4.1.1\n",
            "urllib3==2.0.7\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wasabi==1.1.2\n",
            "wcwidth==0.2.12\n",
            "webcolors==1.13\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.7.0\n",
            "Werkzeug==3.0.1\n",
            "widgetsnbextension==3.6.6\n",
            "wordcloud==1.9.2\n",
            "wrapt==1.14.1\n",
            "xarray==2023.7.0\n",
            "xarray-einstats==0.6.0\n",
            "xgboost==2.0.2\n",
            "xlrd==2.0.1\n",
            "xxhash==3.4.1\n",
            "xyzservices==2023.10.1\n",
            "yarl==1.9.3\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.32\n",
            "zict==3.0.0\n",
            "zipp==3.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data_generator.py"
      ],
      "metadata": {
        "id": "UESElOwm_603"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HERRAMIENTAS\n",
        "\n"
      ],
      "metadata": {
        "id": "vfnzlwCNQClV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from PIL import Image\n",
        "import os.path\n",
        "\"\"\"\n",
        "This code is highly influenced by the implementation of:\n",
        "https://github.com/joelthchao/tensorflow-finetune-flickr-style/dataset.py\n",
        "\"\"\"\n",
        "\n",
        "class ImageDataGenerator:\n",
        "    def __init__(self, batch_size, height, width, z_dim, shuffle=True,\n",
        "                 scale_size=(64, 64), classes=5,root_folder='/content/drive/MyDrive/Pruebas-Tesis/TrainingSet_CACD2000.zip/', mode='train'):\n",
        "\n",
        "        # Init params\n",
        "        self.root_folder = root_folder\n",
        "        if mode == 'train':\n",
        "            self.file_folder = '/content/drive/MyDrive/Pruebas-Tesis/tren_datos/'\n",
        "            self.class_lists = ['train_age_group_0.txt',\n",
        "                               'train_age_group_1.txt',\n",
        "                               'train_age_group_2.txt',\n",
        "                               'train_age_group_3.txt',\n",
        "                               'train_age_group_4.txt']\n",
        "            self.pointer = [0, 0, 0, 0, 0]\n",
        "        else:\n",
        "            self.file_folder = '/content/drive/MyDrive/Pruebas-Tesis/test_data/'\n",
        "            self.class_lists = ['test_age_group_0.txt',\n",
        "                               'test_age_group_1.txt',\n",
        "                               'test_age_group_2.txt',\n",
        "                               'test_age_group_3.txt',\n",
        "                               'test_age_group_4.txt']\n",
        "            self.pointer = [0, 0, 0, 0, 0, 0]\n",
        "\n",
        "        self.train_label_pair = '/content/drive/MyDrive/Pruebas-Tesis/train_label_pair.txt'\n",
        "        self.true_labels = []\n",
        "        self.false_labels = []\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        self.data_size = []\n",
        "        self.n_classes = classes\n",
        "        self.shuffle = shuffle\n",
        "        self.scale_size = scale_size\n",
        "        self.label_pair_index = 0\n",
        "\n",
        "        self.mean = np.array([104., 117., 124.])\n",
        "        self.batch_size = batch_size\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.z_dim = z_dim\n",
        "        self.img_size = self.height\n",
        "\n",
        "        #self.read_class_list(self.class_lists)\n",
        "        if self.shuffle:\n",
        "            self.shuffle_data(shuffle_all=True)\n",
        "\n",
        "        self.get_age_labels()\n",
        "        self.label_features_128, _ = self.pre_generate_labels(batch_size, 128, 128)\n",
        "        self.label_features_64, self.one_hot_labels = self.pre_generate_labels(batch_size, 64, 64)\n",
        "\n",
        "#Función para iterar a través de instancias de una clase, la clase es\n",
        "#ImageDataGenerator se ejecuta la función y devuelve el mismo objeto \"self\"\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "#La funcíón crea una lista de etiquetas de edad la cual contiene ceros, unos, dos, tres y cuatro\n",
        "# dependiendo del tamaño del lote el cual se especifica en \"batch_size\"\n",
        "\n",
        "    def get_age_labels(self):\n",
        "        batch_size = self.batch_size\n",
        "        self.age_label = []\n",
        "        self.age_label.append(np.zeros(batch_size, np.int32))\n",
        "        self.age_label.append(np.ones(batch_size, np.int32))\n",
        "        self.age_label.append(np.ones(batch_size, np.int32)*2)\n",
        "        self.age_label.append(np.ones(batch_size, np.int32) * 3)\n",
        "        self.age_label.append(np.ones(batch_size, np.int32) * 4)\n",
        "\n",
        "# Crea listas de características y etiquetas para un conjunto de clases \"n_classes\"\n",
        "# Las caracaterísticas se van a utilizar para manipular los datos de las imegnes y generar lotes de datos\n",
        "\n",
        "    def pre_generate_labels(self, batch_size, height, width):\n",
        "        # características y una etiqueta activa para cada muestra, n_class kinds\n",
        "        features = []\n",
        "        one_hot_labels = []\n",
        "        full_1 = np.ones((height, width))\n",
        "\n",
        "        for i in range(self.n_classes):\n",
        "            temp = np.zeros((height, width, self.n_classes))\n",
        "            temp[:, :, i] = full_1\n",
        "            features.append(temp)\n",
        "\n",
        "            temp = np.zeros((1, self.n_classes))\n",
        "            temp[0, i] = 1\n",
        "            one_hot_labels.append(temp)\n",
        "\n",
        "        # características y una etiqueta caliente para un lote, n_class kinds\n",
        "        batch_label_features = []\n",
        "        batch_one_hot_labels = []\n",
        "        for i in range(self.n_classes):\n",
        "            temp_label_features = np.zeros((batch_size, height, width, self.n_classes))\n",
        "            temp_label = np.zeros((batch_size, self.n_classes))\n",
        "\n",
        "            for j in range(batch_size):\n",
        "                temp_label_features[j, :, :, :] = features[i]\n",
        "                temp_label[j, :] = one_hot_labels[i]\n",
        "\n",
        "            batch_label_features.append(temp_label_features)\n",
        "            batch_one_hot_labels.append(temp_label)\n",
        "\n",
        "        return batch_label_features, batch_one_hot_labels\n",
        "\n",
        "#Lee listas de clases, contienen rutas a imagenes y etiquetas asociadas\n",
        "#Los datos se almacenan en las variables \"images\" y \"labels\"\n",
        "\n",
        "    def read_class_list(self, class_lists):\n",
        "        \"\"\"\n",
        "        Escanee el archivo de imagen y obtenga las rutas y etiquetas de la imagen.\n",
        "        \"\"\"\n",
        "        for i in range(len(class_lists)):\n",
        "            f = open(self.file_folder + class_lists[i], 'r')\n",
        "            lines = f.readlines()\n",
        "            f.close()\n",
        "            images = []\n",
        "            labels = []\n",
        "            for l in lines:\n",
        "                items = l.split()\n",
        "                images.append(items[0])\n",
        "                labels.append(int(i))\n",
        "\n",
        "            self.images.append(images)\n",
        "            self.labels.append(labels)\n",
        "            # almacenar el número total de datos\n",
        "            self.data_size.append(len(labels))\n",
        "\n",
        "        with open(self.train_label_pair) as f:\n",
        "            lines = f.readlines()\n",
        "            random.shuffle(lines)\n",
        "            for line in lines:\n",
        "                item = line.split()\n",
        "                self.true_labels.append(int(item[0]))\n",
        "                self.false_labels.append(int(item[1]))\n",
        "\n",
        "# Función para obtener lote de imagenes y datos relacionados, selecciona un índice,\n",
        "# se leen las rutas de las imágenes correspondientes y se procesan las imágenes\n",
        "# Se generan etiquetas y datos adicionales y se devuelven como un lote.\n",
        "\n",
        "    def next_batch(self):\n",
        "        \"\"\"\n",
        "        Esta función obtiene las siguientes n  ( = batch_size) imágenes de la lista de rutas\n",
        "        y etiqueta y carga las imágenes en la memoria\n",
        "        \"\"\"\n",
        "        # Obtenga el siguiente lote de imágenes (ruta) y etiquetas\n",
        "        index = random.randint(0, 4)\n",
        "\n",
        "        paths = self.images[index][self.pointer[index]:self.pointer[index] + self.batch_size]\n",
        "\n",
        "        #Leer imágenes\n",
        "        images = np.ndarray([self.batch_size, self.scale_size[0], self.scale_size[1], 3])\n",
        "        for i in range(len(paths)):\n",
        "            images[i] = process_target_img(self.root_folder, paths[i], self.scale_size[0])\n",
        "\n",
        "        # puntero de actualización\n",
        "        self.pointer[index] += self.batch_size\n",
        "        if self.pointer[index] >= (self.data_size[index] - self.batch_size):\n",
        "            self.reset_pointer(index)\n",
        "\n",
        "        label_list = [0, 1, 2, 3, 4]\n",
        "        label_list.remove(index)\n",
        "        random.shuffle(label_list)\n",
        "        error_label = label_list[0]\n",
        "\n",
        "        batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n",
        "\n",
        "        return images, batch_z, self.one_hot_labels[index], self.label_features_64[index], \\\n",
        "               self.label_features_64[error_label], index\n",
        "\n",
        "# Esta función es similar a next_batch,\n",
        "# utiliza procesamiento en paralelo (multiproceso)\n",
        "# para cargar y procesar imágenes de manera más eficiente.\n",
        "\n",
        "\n",
        "    def mp_next_batch(self):\n",
        "        index = random.randint(0, 4)\n",
        "        paths = self.images[index][self.pointer[index]:self.pointer[index] + self.batch_size]\n",
        "        # puntero de actualización\n",
        "        self.pointer[index] += self.batch_size\n",
        "        if self.pointer[index] >= (self.data_size[index] - self.batch_size):\n",
        "            self.reset_pointer(index)\n",
        "        pool = mp.Pool(processes=4)\n",
        "        images = [pool.apply_async(process_target_img, args=(self.root_folder, path, self.scale_size[0]))\n",
        "                  for path in paths]\n",
        "        images = [p.get() for p in images]\n",
        "        images = np.concatenate(images, axis=0)\n",
        "\n",
        "        label_list = [0, 1, 2, 3, 4]\n",
        "        label_list.remove(index)\n",
        "        random.shuffle(label_list)\n",
        "        error_label = label_list[0]\n",
        "\n",
        "        batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n",
        "\n",
        "        return images, batch_z, self.one_hot_labels[index], self.label_features_64[index], \\\n",
        "               self.label_features_64[error_label], index\n",
        "\n",
        "# Mezclara aleatoriamente las rutas de las imagenes, se mezclan para evitar que las imágenes\n",
        "# se presenten en un orden específico lo que puede sesgar el entrenamiento de un modelo de aprendizaje automatico\n",
        "#-El parámetro \"index\" se utiliza para especificar el grupo de imágenes que se mezclaran, al ser \"ndex=None\" se mezclan todas la imágenes\n",
        "#Si \"shuffle_all\" fuera True, se mezclan todas las imágenes, independientemente del valor de \"index\"\n",
        "\n",
        "    def shuffle_data(self, index=None, shuffle_all=False):\n",
        "        \"\"\"\n",
        "        Mezcla aleatoria de imágenes, ya que un grupo de imágenes tiene la misma etiqueta, por lo que no mezclamos etiquetas\n",
        "        \"\"\"\n",
        "        if shuffle_all:\n",
        "            for i in range(len(self.images)):\n",
        "                random.shuffle(self.images[i])\n",
        "        else:\n",
        "            if index:\n",
        "                random.shuffle(self.images[index])\n",
        "\n",
        "#Función que restablece el puntero que realiza el seguimiento de posición actual al comenzar el grupo de imágenes\n",
        "# identificado por \"index\", se utilizara para volver al principio de las imágenes cuando llego a su fin\n",
        "\n",
        "    def reset_pointer(self, index):\n",
        "        \"\"\"\n",
        "        restablecer el puntero al comienzo de la lista\n",
        "        \"\"\"\n",
        "        self.pointer[index] = 0\n",
        "\n",
        "        if self.shuffle:\n",
        "            self.shuffle_data(index)\n",
        "\n",
        "#Método que se utiliza para obtener un lote de imágenes de origen\n",
        "#Con el indice \"index\" se selecciona un lote de imágenes de ese grupo y las procesa con el método\n",
        "# \"process_source_img\", avanza el puntero para señalar el siguiente lote de imágenes.\n",
        "\n",
        "    def process_source_img(self, img_path, image_size, mean, scale):\n",
        "        img = cv2.imread(self.root_folder + img_path)\n",
        "        img = img[:, :, [2, 1, 0]]\n",
        "        # cambiar la escala de la imagen\n",
        "        img = cv2.resize(img, (image_size, image_size))\n",
        "        img = img.astype(np.float32)\n",
        "        img = (img - mean) * scale\n",
        "        return img\n",
        "\n",
        "#Método que se utiliza para obtener un lote de imágenes de origen\n",
        "#Con el indice \"index\" se selecciona un lote de imágenes de ese grupo y las procesa con el método\n",
        "# \"process_source_img\", avanza el puntero para señalar el siguiente lote de imágenes\n",
        "\n",
        "\n",
        "    def next_source_imgs(self, index, image_size, batch_size, mean=np.array([104., 117., 124.]), scale=1.):\n",
        "        paths = self.images[index][self.pointer[index]:self.pointer[index] + batch_size]\n",
        "        # Leer imágenes\n",
        "        images = np.ndarray([batch_size, image_size, image_size, 3])\n",
        "        for i in range(len(paths)):\n",
        "            images[i] = self.process_source_img(paths[i], image_size, mean, scale)\n",
        "\n",
        "        # puntero de actualización\n",
        "        self.pointer[index] += batch_size\n",
        "        if self.pointer[index] >= (self.data_size[index] - batch_size):\n",
        "            self.reset_pointer(index)\n",
        "\n",
        "        return images, paths\n",
        "\n",
        "#Método que se utiliza para obtener un lote de imágenes de destino y un lote de imágenes de origen.\n",
        "#Selecciona un grupo de imágenes de destino (index obtenido a través de self.true_labels) y procesa las imágenes de destino utilizando el método process_target_img.\n",
        "#obtiene un lote de imágenes de origen utilizando el método next_source_imgs\n",
        "\n",
        "    def next_batch_transfer(self, source_index, source_image_size=227):\n",
        "        index = self.true_labels[self.label_pair_index]\n",
        "        paths = self.images[index][self.pointer[index]:self.pointer[index] + self.batch_size]\n",
        "        # Leer imágenes\n",
        "        imgs = np.ndarray([self.batch_size, self.scale_size[0], self.scale_size[1], 3])\n",
        "        for i in range(len(paths)):\n",
        "            imgs[i] = process_target_img(self.root_folder, paths[i], self.scale_size[0])\n",
        "        # puntero de actualización\n",
        "        self.pointer[index] += self.batch_size\n",
        "        if self.pointer[index] >= (self.data_size[index] - self.batch_size):\n",
        "            self.reset_pointer(index)\n",
        "\n",
        "        error_label = self.false_labels[self.label_pair_index]\n",
        "        self.label_pair_index += 1\n",
        "\n",
        "        source_imgs = self.next_source_imgs(source_index, source_image_size)\n",
        "\n",
        "        return imgs, source_imgs, self.one_hot_labels[index], self.label_features[index], \\\n",
        "               self.label_features[error_label], index\n",
        "\n",
        "# este método se utiliza para obtener un lote de imágenes de destino y un lote de imágenes de origen,\n",
        "# incluye etiquetas de edad. Realiza operaciones similares a next_batch_transfer,\n",
        "# obtiene etiquetas de edad y las incluye en la salida.\n",
        "\n",
        "    def next_age_batch_transfer(self, source_index):\n",
        "        index = self.true_labels[self.label_pair_index]\n",
        "        paths = self.images[index][self.pointer[index]:self.pointer[index] + self.batch_size]\n",
        "        # Leer imagenes\n",
        "        imgs = np.ndarray([self.batch_size, self.scale_size[0], self.scale_size[1], 3])\n",
        "        for i in range(len(paths)):\n",
        "            imgs[i] = process_target_img(self.root_folder, paths[i], self.scale_size[0])\n",
        "        # puntero de actualización\n",
        "        self.pointer[index] += self.batch_size\n",
        "        if self.pointer[index] >= (self.data_size[index] - self.batch_size):\n",
        "            self.reset_pointer(index)\n",
        "\n",
        "        error_label = self.false_labels[self.label_pair_index]\n",
        "        self.label_pair_index += 1\n",
        "\n",
        "        source_imgs = self.next_source_imgs(source_index)\n",
        "\n",
        "        return imgs, source_imgs, self.one_hot_labels[index], self.label_features[index], \\\n",
        "               self.label_features[error_label], self.age_label[index], index\n",
        "\n",
        "#Método que se utiliza para obtener un lote de imágenes de destino.\n",
        "#Selecciona un grupo de imágenes\n",
        "#de destino y procesa las imágenes utilizando el método process_target_img.\n",
        "\n",
        "    def next_target_imgs(self, index):\n",
        "        paths = self.images[index][self.pointer[index]:self.pointer[index] + self.batch_size]\n",
        "        # Leer imagenes\n",
        "        imgs = np.ndarray([self.batch_size, self.scale_size[0], self.scale_size[1], 3])\n",
        "        for i in range(len(paths)):\n",
        "            imgs[i] = process_target_img(self.root_folder, paths[i], self.scale_size[0])\n",
        "        # puntero de actualización\n",
        "        self.pointer[index] += self.batch_size\n",
        "        if self.pointer[index] >= (self.data_size[index]- self.batch_size):\n",
        "            self.reset_pointer(index)\n",
        "\n",
        "        return imgs\n",
        "\n",
        "#se utiliza para obtener un lote de imágenes de destino que se utilizarán en un modelo GAN (Red Generativa Adversaria).\n",
        "# Se selecciona aleatoriamente un grupo de imágenes de destino y se procesan las imágenes.\n",
        "#se genera un lote de variables aleatorias batch_z que se utiliza en el modelo GAN.\n",
        "\n",
        "    def next_gan_batch(self):\n",
        "        index = random.randint(0, 4)\n",
        "        paths = self.images[index][self.pointer[index]:self.pointer[index] + self.batch_size]\n",
        "        # Leer imagenes\n",
        "        imgs = np.ndarray([self.batch_size, self.scale_size[0], self.scale_size[1], 3])\n",
        "        for i in range(len(paths)):\n",
        "            imgs[i] = process_target_img2(self.root_folder, paths[i], self.scale_size[0])\n",
        "        # puntero de actualización\n",
        "        self.pointer[index] += self.batch_size\n",
        "        if self.pointer[index] >= (self.data_size[index]- self.batch_size):\n",
        "            self.reset_pointer(index)\n",
        "\n",
        "        batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n",
        "\n",
        "        return imgs, batch_z\n",
        "\n",
        "#Este método se utiliza para cargar un lote de imágenes junto con etiquetas\n",
        "#Selecciona un grupo de imágenes identificado por index y carga las imágenes, las etiqueta y las rutas de las imágenes.\n",
        "\n",
        "    def load_batch(self, index):\n",
        "        paths = self.images[index][self.pointer[index]:self.pointer[index] + self.batch_size]\n",
        "        # Leer imagenes\n",
        "        imgs = np.ndarray([self.batch_size, 227, 227, 3])\n",
        "        for i in range(len(paths)):\n",
        "            imgs[i] = process_source_img(self.root_folder, paths[i], self.mean)\n",
        "        # puntero de actualización\n",
        "        self.pointer[index] += self.batch_size\n",
        "\n",
        "        return imgs, self.one_hot_labels[index], paths\n",
        "\n",
        "#Este método se utiliza para cargar imágenes de un directorio específico (data_dir).\n",
        "# Lee todas las imágenes en ese directorio, las cambia de escala\n",
        "# al tamaño especificado (img_size) y las almacena en una matriz junto con las rutas de las imágenes.\n",
        "\n",
        "    def load_imgs(self, data_dir, img_size=128):\n",
        "        paths = os.listdir(data_dir)\n",
        "        # Leer imagenes\n",
        "        imgs = np.ndarray([len(paths), img_size, img_size, 3])\n",
        "        for i in range(len(paths)):\n",
        "            img = cv2.imread(os.path.join(data_dir, paths[i]))\n",
        "            img = img[:, :, [2, 1, 0]]\n",
        "            # cambiar la escala de la imagen\n",
        "            img = cv2.resize(img, (img_size, img_size))\n",
        "            img = img.astype(np.float32)\n",
        "            img -= self.mean\n",
        "            imgs[i] = img\n",
        "\n",
        "        return imgs, paths\n",
        "\n",
        "#Este método guarda un lote de imágenes en un directorio especificado.\n",
        "# Toma un lote de imágenes batch_imgs, una lista de nombres de imágenes img_names,\n",
        "# un directorio de destino folder, y opcionalmente un índice y una bandera if_target.\n",
        "# Las imágenes en el lote se ajustan y se convierten a tipo de dato uint8 antes de guardarlas en el directorio.\n",
        "#Si la bandera if_target es verdadera, se aplica un ajuste diferente que involucra escalar las imágenes.\n",
        "#Las imágenes se guardan con un nombre basado en los nombres de imágenes originales y, opcionalmente, un índice.\n",
        "\n",
        "    def save_batch(self, batch_imgs, img_names, folder, index=None, if_target=True):\n",
        "        assert batch_imgs.shape[0] == len(img_names), 'img nums must match img names'\n",
        "        shape = batch_imgs.shape[1:]\n",
        "        for i in range(batch_imgs.shape[0]):\n",
        "            img = np.reshape(batch_imgs[i, :, :, :], shape)\n",
        "            if if_target:\n",
        "                im = np.uint8((img + 1.)*127.5)\n",
        "            else:\n",
        "                im = np.uint8((img + self.mean))\n",
        "\n",
        "            if (im.shape[2] == 1):\n",
        "                im = Image.fromarray(np.reshape(im, [im.shape[0], im.shape[1]]), 'L')  # gray image\n",
        "            else:\n",
        "                im = Image.fromarray(im)\n",
        "            if index is not None:\n",
        "                im.save(os.path.join(folder, img_names[i] + '_' + str(index) + '.jpg'))\n",
        "            else:\n",
        "                im.save(os.path.join(folder, img_names[i]))\n",
        "\n",
        "#Este método se utiliza para obtener un lote de imágenes de origen.\n",
        "# Dado un índice index, selecciona un grupo de imágenes de ese grupo y las procesa mediante el método process_source_img.\n",
        "# Luego, devuelve dos conjuntos de imágenes, uno escalado a 227x227 píxeles y otro escalado a 128x128 píxeles.\n",
        "\n",
        "    def next_source_imgs2(self, index):\n",
        "        # index = 0\n",
        "        paths = self.images[index][self.pointer[index]:self.pointer[index] + self.batch_size]\n",
        "        # Leer imagenes\n",
        "        images_227 = np.ndarray([self.batch_size, 227, 227, 3])\n",
        "        images_128 = np.ndarray([self.batch_size, 128, 128, 3])\n",
        "        for i in range(len(paths)):\n",
        "            image = cv2.imread(self.root_folder + paths[i])\n",
        "            image = image[:, :, [2, 1, 0]]\n",
        "            # cambiar la escala de la imagen\n",
        "            img = cv2.resize(image, (227, 227))\n",
        "            img = img.astype(np.float32)\n",
        "            img -= self.mean\n",
        "            images_227[i] = img\n",
        "\n",
        "            img = cv2.resize(image, (128, 128))\n",
        "            img = img.astype(np.float32)\n",
        "            img -= self.mean\n",
        "            images_128[i] = img\n",
        "        # puntero de actualización\n",
        "        self.pointer[index] += self.batch_size\n",
        "        if self.pointer[index] >= (self.data_size[index]- self.batch_size):\n",
        "            self.reset_pointer(index)\n",
        "\n",
        "        return images_227, images_128\n",
        "\n",
        "#Este método se utiliza para obtener un lote de imágenes de destino y un lote de imágenes de origen.\n",
        "#Se determina el índice del grupo de destino seleccionando index de self.true_labels usando self.label_pair_index.\n",
        "#Luego, se obtiene un conjunto de rutas de imágenes de destino (paths) desde el grupo de imágenes correspondiente.\n",
        "# Se crea un arreglo vacío \"imgs\" para almacenar las imágenes de destino,\n",
        "# se recorren las rutas de las imágenes, y para cada imagen se llama a la función process_target_img para cargar,\n",
        "# procesar y ajustar la imagen. Estas imágenes procesadas se almacenan en imgs.\n",
        "# Se actualiza el puntero de índice del grupo de destino y,\n",
        "#si es necesario, se restablece a cero usando el método reset_pointer.\n",
        "# se obtienen las imágenes de origen (escaladas a 227x227 y 128x128) llamando al método next_source_imgs2(source_index).\n",
        "# se devuelve un conjunto de imágenes de destino, imágenes de origen, etiquetas y otras características.\n",
        "\n",
        "    def next_batch_transfer2(self, source_index=0):\n",
        "        index = self.true_labels[self.label_pair_index]\n",
        "        paths = self.images[index][self.pointer[index]:self.pointer[index] + self.batch_size]\n",
        "        # Leer imagenes\n",
        "        imgs = np.ndarray([self.batch_size, self.scale_size[0], self.scale_size[1], 3])\n",
        "        for i in range(len(paths)):\n",
        "            imgs[i] = process_target_img(self.root_folder, paths[i], self.scale_size[0])\n",
        "        # puntero de actualización\n",
        "        self.pointer[index] += self.batch_size\n",
        "        if self.pointer[index] >= (self.data_size[index] - self.batch_size):\n",
        "            self.reset_pointer(index)\n",
        "\n",
        "        error_label = self.false_labels[self.label_pair_index]\n",
        "        self.label_pair_index += 1\n",
        "\n",
        "        images_227, images_128 = self.next_source_imgs2(source_index)\n",
        "\n",
        "        return imgs, images_227, images_128, self.one_hot_labels[index], self.label_features[index], \\\n",
        "               self.label_features[error_label], self.age_label[index], index\n",
        "\n",
        "#Similar al next_batch_transfer2, pero solo se obtiene un lote de imágenes de destino y no se incluyen imágenes de origen.\n",
        "\n",
        "    def next_target_batch_transfer(self):\n",
        "        index = self.true_labels[self.label_pair_index]\n",
        "        paths = self.images[index][self.pointer[index]:self.pointer[index] + self.batch_size]\n",
        "        # Leer imagenes\n",
        "        imgs = np.ndarray([self.batch_size, self.scale_size[0], self.scale_size[1], 3])\n",
        "        for i in range(len(paths)):\n",
        "            imgs[i] = process_target_img(self.root_folder, paths[i], self.scale_size[0])\n",
        "        # puntero de actualización\n",
        "        self.pointer[index] += self.batch_size\n",
        "        if self.pointer[index] >= (self.data_size[index] - self.batch_size):\n",
        "            self.reset_pointer(index)\n",
        "\n",
        "        error_label = self.false_labels[self.label_pair_index]\n",
        "        self.label_pair_index += 1\n",
        "\n",
        "        return imgs, self.one_hot_labels[index], self.label_features_64[index], \\\n",
        "               self.label_features_64[error_label], self.age_label[index]\n",
        "\n",
        "#Este método se utiliza para obtener un lote de imágenes de destino y sus características correspondientes.\n",
        "#También realiza operaciones similares a next_batch_transfer2\n",
        "\n",
        "    def next(self):\n",
        "        index = self.true_labels[self.label_pair_index]\n",
        "        paths = self.images[index][self.pointer[index]:self.pointer[index] + self.batch_size]\n",
        "        # Leer imagenes\n",
        "        imgs = np.ndarray([self.batch_size, self.scale_size[0], self.scale_size[1], 3])\n",
        "        for i in range(len(paths)):\n",
        "            imgs[i] = process_target_img(self.root_folder, paths[i], self.scale_size[0])\n",
        "\n",
        "        # puntero de actualización\n",
        "        self.pointer[index] += self.batch_size\n",
        "        if self.pointer[index] >= (self.data_size[index] - self.batch_size):\n",
        "            self.reset_pointer(index)\n",
        "\n",
        "        error_label = self.false_labels[self.label_pair_index]\n",
        "        self.label_pair_index += 1\n",
        "\n",
        "        return (imgs, self.label_features_128[index], self.label_features_64[index],\n",
        "                self.label_features_64[error_label], self.age_label[index])\n",
        "\n",
        "#Función que selecciona aleatoriamente un grupo de imágenes y obtiene un lote de imágenes de destino, genera un lote de variables aleatorias batch_z.\n",
        "#Utiliza el módulo concurrent.futures para procesar las imágenes de destino en paralelo, lo que puede acelerar la carga y procesamiento de imágenes.\n",
        "#El método también maneja la selección de una etiqueta de error para su uso en el aprendizaje automático.\n",
        "\n",
        "    def my_next_batch(self):\n",
        "        index = random.randint(0, 4)\n",
        "        paths = self.images[index][self.pointer[index]:self.pointer[index] + self.batch_size]\n",
        "        self.pointer[index] += self.batch_size\n",
        "        if self.pointer[index] >= (self.data_size[index] - self.batch_size):\n",
        "            self.reset_pointer(index)\n",
        "\n",
        "        folder_lists = [self.root_folder for i in range(self.batch_size)]\n",
        "        img_sizes = [self.scale_size[0] for i in range(self.batch_size)]\n",
        "        imgs = []\n",
        "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "            for img in executor.map(process_target_img, folder_lists, paths, img_sizes):\n",
        "                imgs.append(img)\n",
        "        imgs = np.array(imgs)\n",
        "\n",
        "        label_list = [0, 1, 2, 3, 4]\n",
        "        label_list.remove(index)\n",
        "        random.shuffle(label_list)\n",
        "        error_label = label_list[0]\n",
        "        batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n",
        "\n",
        "        return imgs, batch_z, self.one_hot_labels[index], self.label_features[index], self.label_features[error_label], index\n",
        "\n",
        "#Funciones auxiliares: process_target_img, process_target_img2, process_source_img\n",
        "#Se utilizan para cargar imágenes desde rutas, cambiar su escala y realizar ajustes en los valores de los píxeles según sea necesario.\n",
        "\n",
        "def process_target_img(root_folder, img_path, img_size):\n",
        "    img = cv2.imread(root_folder + img_path)\n",
        "    img = img[:, :, [2, 1, 0]]\n",
        "    # cambiar la escala de la imagen\n",
        "    img = cv2.resize(img, (img_size, img_size))\n",
        "    img = img.astype(np.float32)\n",
        "    img = img / 127.5 - 1.\n",
        "    return img\n",
        "\n",
        "\n",
        "def process_target_img2(root_folder, img_path, img_size):\n",
        "    img = cv2.imread(root_folder + img_path)\n",
        "    img = img[:, :, [2, 1, 0]]\n",
        "    # cambiar la escala de la imagen\n",
        "    img = cv2.resize(img, (img_size, img_size))\n",
        "    img = img.astype(np.float32)\n",
        "    img = img / 255.\n",
        "    return img\n",
        "\n",
        "\n",
        "def process_source_img(root_folder, img_path, mean):\n",
        "    img = cv2.imread(root_folder + img_path)\n",
        "    img = img[:, :, [2, 1, 0]]\n",
        "    # cambiar la escala de la imagen\n",
        "    img = cv2.resize(img, (227, 227))\n",
        "    img = img.astype(np.float32)\n",
        "    img -= mean\n",
        "    return img\n",
        "\n",
        "#Este método se utiliza para cargar un lote de imágenes de destino desde un grupo aleatorio.\n",
        "# Realiza operaciones similares a process_target_img para cargar, procesar y ajustar las imágenes antes de devolverlas.\n",
        "\n",
        "def load_target_batch(self):\n",
        "    index = random.randint(1, 4)\n",
        "    paths = self.images[index][self.pointer[index]:self.pointer[index] + self.batch_size]\n",
        "    # puntero de actualización\n",
        "    self.pointer[index] += self.batch_size\n",
        "    if self.pointer[index] >= (self.data_size[index] - self.batch_size):\n",
        "        self.reset_pointer(index)\n",
        "    # Leer imagenes\n",
        "    folder_lists = [self.root_folder for i in range(self.batch_size)]\n",
        "    img_sizes = [self.scale_size[0] for i in range(self.batch_size)]\n",
        "    imgs = []\n",
        "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "        for img in executor.map(process_target_img, folder_lists, paths, img_sizes):\n",
        "            imgs.append(img)\n",
        "    imgs = np.array(imgs)\n",
        "\n",
        "    return imgs\n",
        "\n",
        "\n",
        "#Similar al método next_source_imgs2, este método se utiliza para obtener un lote de imágenes de origen.\n",
        "#También realiza operaciones de lectura y procesamiento de imágenes en paralelo, utilizando concurrent.futures para acelerar el proceso.\n",
        "def next_source_imgs(self):\n",
        "    index = 1\n",
        "    paths = self.images[index][self.pointer[index]:self.pointer[index] + self.batch_size]\n",
        "    # puntero de actualización\n",
        "    self.pointer[index] += self.batch_size\n",
        "    if self.pointer[index] >= (self.data_size[index] - self.batch_size):\n",
        "        self.reset_pointer(index)\n",
        "    # Leer imagenes\n",
        "    folder_lists = [self.root_folder for i in range(self.batch_size)]\n",
        "    img_means = [self.mean for i in range(self.batch_size)]\n",
        "    imgs = []\n",
        "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "        for img in executor.map(process_source_img, folder_lists, paths, img_means):\n",
        "            imgs.append(img)\n",
        "    return imgs"
      ],
      "metadata": {
        "id": "TdLFOpIm4sas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ops.py"
      ],
      "metadata": {
        "id": "56Si0Ib8Q4kH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install \tjax==0.4.20\n",
        "\n"
      ],
      "metadata": {
        "id": "RPCqAYFpsTVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade jax"
      ],
      "metadata": {
        "id": "3e6zfifJqorV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!jupyter notebook stop\n",
        "#!jupyter notebook"
      ],
      "metadata": {
        "id": "aiXLSKXnq17o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n"
      ],
      "metadata": {
        "id": "iHhTYgI4q3JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "\n",
        "\n",
        "#Esta clase define una capa de normalización de lotes para su uso en una red neuronal.\n",
        "#Proporciona operaciones de normalización de lotes tanto en modo de entrenamiento como en modo de evaluación.\n",
        "#También utiliza el método de media exponencial móvil para ajustar los parámetros de normalización\n",
        "\n",
        "class batch_norm(object):\n",
        "    \"\"\"Code modification of http://stackoverflow.com/a/33950177\"\"\"\n",
        "\n",
        "    def __init__(self, epsilon=1e-5, momentum=0.9, name=\"batch_norm\"):\n",
        "        with tf.variable_scope(name):\n",
        "            self.epsilon = epsilon\n",
        "            self.momentum = momentum\n",
        "\n",
        "            self.ema = tf.train.ExponentialMovingAverage(decay=self.momentum)\n",
        "            self.name = name\n",
        "\n",
        "#El método __call__ se encarga de aplicar la normalización de lotes a los datos de entrada.\n",
        "#Si train es True, realiza la normalización en el modo de entrenamiento; de lo contrario, utiliza los valores acumulados durante el entrenamiento.\n",
        "\n",
        "    def __call__(self, x, train=True):\n",
        "        shape = x.get_shape().as_list()\n",
        "\n",
        "        if train:\n",
        "            with tf.variable_scope(self.name) as scope:\n",
        "                self.beta = tf.get_variable(\"beta\", [shape[-1]],\n",
        "                                            initializer=tf.constant_initializer(0.))\n",
        "                self.gamma = tf.get_variable(\"gamma\", [shape[-1]],\n",
        "                                             initializer=tf.random_normal_initializer(1., 0.02))\n",
        "\n",
        "                batch_mean, batch_var = tf.nn.moments(x, [0, 1, 2], name='moments')\n",
        "                with tf.variable_scope(tf.get_variable_scope(), reuse=False):\n",
        "                    ema_apply_op = self.ema.apply([batch_mean, batch_var])\n",
        "                self.ema_mean, self.ema_var = self.ema.average(batch_mean), self.ema.average(batch_var)\n",
        "\n",
        "                with tf.control_dependencies([ema_apply_op]):\n",
        "                    mean, var = tf.identity(batch_mean), tf.identity(batch_var)\n",
        "        else:\n",
        "            mean, var = self.ema_mean, self.ema_var\n",
        "\n",
        "        normed = tf.nn.batch_norm_with_global_normalization(\n",
        "            x, mean, var, self.beta, self.gamma, self.epsilon, scale_after_normalization=True)\n",
        "\n",
        "        return normed\n",
        "\n",
        "#Funciones para Operaciones de Capa:\n",
        "\n",
        "#conv: Esta función se utiliza para aplicar una operación de convolución en 2D a los datos de entrada.\n",
        "#Puede manejar grupos de entrada y utiliza pesos y sesgos.\n",
        "\n",
        "def conv(x, filter_height, filter_width, num_filters, stride_y, stride_x, name,\n",
        "         padding='SAME', groups=1):\n",
        "    \"\"\"\n",
        "    Adapted from: https://github.com/ethereon/caffe-tensorflow\n",
        "    \"\"\"\n",
        "    # Obtener número de canales de entrada\n",
        "    input_channels = int(x.get_shape()[-1])\n",
        "\n",
        "    # Crear función lambda para la convolución.\n",
        "    convolve = lambda i, k: tf.nn.conv2d(i, k, strides=[1, stride_y, stride_x, 1], padding=padding)\n",
        "\n",
        "    with tf.variable_scope(name) as scope:\n",
        "        #Cree variables tf para los pesos y sesgos de la capa de conversión\n",
        "        weights = tf.get_variable('weights', shape=[filter_height, filter_width, input_channels / groups, num_filters])\n",
        "        biases = tf.get_variable('biases', shape=[num_filters])\n",
        "\n",
        "        if groups == 1:\n",
        "            conv = convolve(x, weights)\n",
        "\n",
        "        #En los casos de grupos múltiples, divida las entradas y pesos y\n",
        "        else:\n",
        "            # Dividir la entrada y los pesos y convolucionarlos por separado\n",
        "            input_groups = tf.split(axis=3, num_or_size_splits=groups, value=x)\n",
        "            weight_groups = tf.split(axis=3, num_or_size_splits=groups, value=weights)\n",
        "            output_groups = [convolve(i, k) for i, k in zip(input_groups, weight_groups)]\n",
        "\n",
        "            # Divida la entrada y los pesos y conviértalos por separado\n",
        "            conv = tf.concat(axis=3, values=output_groups)\n",
        "\n",
        "        # Agregar sesgos\n",
        "        bias = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())\n",
        "\n",
        "        # Aplicar función relu\n",
        "        relu = tf.nn.relu(bias, name=scope.name)\n",
        "\n",
        "        return relu\n",
        "\n",
        "#fc: Esta función se utiliza para aplicar una operación de capa completamente conectada (fully connected) a los datos de entrada.\n",
        "\n",
        "def fc(x, num_in, num_out, name, relu=True):\n",
        "    with tf.variable_scope(name) as scope:\n",
        "\n",
        "        # Crear variables tf para los pesos y sesgos.\n",
        "        weights = tf.get_variable('weights', shape=[num_in, num_out], trainable=True)\n",
        "        biases = tf.get_variable('biases', [num_out], trainable=True)\n",
        "\n",
        "        #Matrix multiplica pesos y entradas y agrega sesgo\n",
        "        act = tf.nn.xw_plus_b(x, weights, biases, name=scope.name)\n",
        "\n",
        "        if relu == True:\n",
        "            # Aplicar la no linealidad de ReLu\n",
        "            relu = tf.nn.relu(act)\n",
        "            return relu\n",
        "        else:\n",
        "            return act\n",
        "\n",
        "#max_pool: Realiza una operación de max-pooling en los datos de entrada.\n",
        "\n",
        "def max_pool(x, filter_height, filter_width, stride_y, stride_x, name, padding='SAME'):\n",
        "    return tf.nn.max_pool(x, ksize=[1, filter_height, filter_width, 1],\n",
        "                          strides=[1, stride_y, stride_x, 1],\n",
        "                          padding=padding, name=name)\n",
        "\n",
        "#lrn: Realiza una normalización local de respuesta en los datos de entrada.\n",
        "\n",
        "def lrn(x, radius, alpha, beta, name, bias=1.0):\n",
        "    return tf.nn.local_response_normalization(x, depth_radius=radius, alpha=alpha,\n",
        "                                              beta=beta, bias=bias, name=name)\n",
        "\n",
        "#dropout: Aplica dropout a los datos de entrada, donde keep_prob es la probabilidad de mantener una neurona activa.\n",
        "def dropout(x, keep_prob):\n",
        "    return tf.nn.dropout(x, keep_prob)\n",
        "\n",
        "#Esta función realiza una convolución 1D en los datos de entrada. Puede aplicarse en datos de una sola dimensión.\n",
        "\n",
        "def conv1d(input, filter_width, out_channels, in_channels=None, stride=1,\n",
        "           HeUniform=False, with_bias=True, name=None):\n",
        "    with tf.variable_scope(name):\n",
        "        if not in_channels:\n",
        "            in_channels = input.get_shape()[-1]\n",
        "        if HeUniform:\n",
        "            n = filter_width * out_channels\n",
        "            std = np.sqrt(2.0 / n)\n",
        "        else:\n",
        "            std=0.02\n",
        "\n",
        "        kernel = tf.get_variable('weights', [filter_width, in_channels, out_channels],\n",
        "                                 initializer=tf.random_normal_initializer(stddev=std))\n",
        "        conv = tf.nn.conv1d(input, kernel, stride=stride, padding='SAME')\n",
        "\n",
        "        if with_bias:\n",
        "            biases = tf.get_variable('b', [out_channels], initializer=tf.constant_initializer(0.0))\n",
        "            conv = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())\n",
        "        return conv\n",
        "\n",
        "#Realiza una convolución 2D en los datos de entrada.\n",
        "#Esta función se utiliza comúnmente en el procesamiento de imágenes. Puede aplicar una convolución con filtros 2D a los datos de entrada.\n",
        "\n",
        "def conv2d(input_, output_dim, k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02,\n",
        "           padding='SAME', name=\"conv2d\"):\n",
        "    \"\"\"\n",
        "    calcula una convolución 2-D dada la entrada 4-D y los tensores de filtro\n",
        "    Dado un tensor de entrada de forma  [batch, in_height, in_width, in_channels]\n",
        "    un tensor de filtro de forma  [filter_height, filter_width,in_channels, out_channels]\n",
        "    \"\"\"\n",
        "    with tf.variable_scope(name):\n",
        "        w = tf.get_variable('weights', [k_h, k_w, input_.get_shape()[-1], output_dim],\n",
        "                            initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
        "        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding=padding)\n",
        "\n",
        "        biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\n",
        "        conv = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())\n",
        "        return conv\n",
        "\n",
        "#Realiza una operación de deconvolución (convolución traspuesta) en datos de entrada en 2D.\n",
        "#Esto es útil para aumentar el tamaño de los mapas de características y se utiliza comúnmente en las capas de deconvolución de una red generativa, como una GAN (Red Generativa Adversaria).\n",
        "#input_: Datos de entrada en forma de tensor 4-D.\n",
        "#output_shape: La forma deseada del tensor de salida después de la deconvolución.\n",
        "#k_h y k_w: Altura y ancho del filtro de deconvolución.\n",
        "#d_h y d_w: Paso o stride en altura y ancho.\n",
        "#stddev: Desviación estándar para la inicialización de pesos.\n",
        "#name: Nombre de la variable de TensorFlow.\n",
        "\n",
        "def deconv2d(input_, output_shape,\n",
        "             k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02,\n",
        "             name=\"deconv2d\"):\n",
        "    \"\"\"\n",
        "    entrada: Un tensor 4-D de tipo float y forma [batch, height, width, in_channels].\n",
        "    filtro: un tensor 4-D con el mismo tipo que valor y forma [height, width, output_channels, in_channels]\n",
        "    La dimensión in_channels del filtro debe coincidir con la del valor.\n",
        "    \"\"\"\n",
        "    with tf.variable_scope(name):\n",
        "        # filter : [height, width, output_channels, in_channels]\n",
        "        w = tf.get_variable('weights', [k_h, k_w, output_shape[-1], input_.get_shape()[-1]],\n",
        "                            initializer=tf.random_normal_initializer(stddev=stddev))\n",
        "        deconv = tf.nn.conv2d_transpose(input_, w, output_shape=output_shape,\n",
        "                                            strides=[1, d_h, d_w, 1])\n",
        "\n",
        "        biases = tf.get_variable('biases', [output_shape[-1]], initializer=tf.constant_initializer(0.0))\n",
        "        deconv = tf.reshape(tf.nn.bias_add(deconv, biases), deconv.get_shape())\n",
        "\n",
        "        return deconv\n",
        "\n",
        "#lrelu (Función):Implementa la función de activación \"Leaky ReLU\" (Rectified Linear Unit con fuga). Esta función ayuda a resolver el problema de la \"unidad muerta\" que puede ocurrir con la ReLU normal. Si x es menor que cero, se multiplica por un valor de fuga (generalmente 0.2) antes de tomar el máximo. Si es mayor o igual a cero, se deja sin cambios.\n",
        "#x: El tensor de entrada.\n",
        "#leak: Valor de fuga (por defecto, 0.2).\n",
        "#name: Nombre de la variable de TensorFlow.\n",
        "\n",
        "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
        "    return tf.maximum(x, leak * x)\n",
        "\n",
        "#linear (Función):Realiza una operación de capa completamente conectada (fully connected) en los datos de entrada.\n",
        "#input_: Datos de entrada.\n",
        "#output_size: Tamaño del tensor de salida.\n",
        "#stddev: Desviación estándar para la inicialización de pesos.\n",
        "#bias_start: Valor inicial para los sesgos.\n",
        "#name: Nombre de la variable de TensorFlow.\n",
        "\n",
        "def linear(input_, output_size, name, stddev=0.02, bias_start=0.0):\n",
        "    shape = input_.get_shape().as_list()\n",
        "    input_ = tf.reshape(input_, [shape[0], -1])\n",
        "    shape = input_.get_shape().as_list()\n",
        "    with tf.variable_scope(name):\n",
        "        matrix = tf.get_variable(\"weights\", [shape[1], output_size], tf.float32,\n",
        "                                 tf.random_normal_initializer(stddev=stddev))\n",
        "\n",
        "        bias = tf.get_variable(\"bias\", [output_size], initializer=tf.constant_initializer(bias_start))\n",
        "\n",
        "        return tf.matmul(input_, matrix) + bias\n",
        "\n",
        "#unravel_argmax (Función):Se utiliza en operaciones de pooling unpooling. Revierte la operación de max-pooling y obtiene las coordenadas originales de los valores máximos.\n",
        "#argmax: Los índices de las posiciones de valor máximo.\n",
        "#shape: La forma de la capa original.\n",
        "\n",
        "def unravel_argmax(argmax, shape):\n",
        "    output_list = [argmax // (shape[2] * shape[3]),\n",
        "                   argmax % (shape[2] * shape[3]) // shape[3]]\n",
        "    return tf.pack(output_list)\n",
        "\n",
        "#unpool_layer2x2_batch (Función):Implementa una operación de unpooling en una capa de 2x2.\n",
        "#Esta función es útil después de una capa de max-pooling para restaurar la resolución original de los datos.\n",
        "#bottom: Datos de entrada a la operación de unpooling.\n",
        "#argmax: Los índices de argmax de la capa de max-pooling.\n",
        "#Realiza una operación de inversión de max-pooling y devuelve los datos de salida.\n",
        "\n",
        "def unpool_layer2x2_batch(bottom, argmax):\n",
        "    bottom_shape = tf.shape(bottom)\n",
        "    top_shape = [bottom_shape[0], bottom_shape[1] * 2, bottom_shape[2] * 2, bottom_shape[3]]\n",
        "\n",
        "    batch_size = top_shape[0]\n",
        "    height = top_shape[1]\n",
        "    width = top_shape[2]\n",
        "    channels = top_shape[3]\n",
        "\n",
        "    argmax_shape = tf.to_int64([batch_size, height, width, channels])\n",
        "    argmax = unravel_argmax(argmax, argmax_shape)\n",
        "\n",
        "    t1 = tf.to_int64(tf.range(channels))\n",
        "    t1 = tf.tile(t1, [batch_size * (width // 2) * (height // 2)])\n",
        "    t1 = tf.reshape(t1, [-1, channels])\n",
        "    t1 = tf.transpose(t1, perm=[1, 0])\n",
        "    t1 = tf.reshape(t1, [channels, batch_size, height // 2, width // 2, 1])\n",
        "    t1 = tf.transpose(t1, perm=[1, 0, 2, 3, 4])\n",
        "\n",
        "    t2 = tf.to_int64(tf.range(batch_size))\n",
        "    t2 = tf.tile(t2, [channels * (width // 2) * (height // 2)])\n",
        "    t2 = tf.reshape(t2, [-1, batch_size])\n",
        "    t2 = tf.transpose(t2, perm=[1, 0])\n",
        "    t2 = tf.reshape(t2, [batch_size, channels, height // 2, width // 2, 1])\n",
        "\n",
        "    t3 = tf.transpose(argmax, perm=[1, 4, 2, 3, 0])\n",
        "\n",
        "    t = tf.concat(4, [t2, t3, t1])\n",
        "    indices = tf.reshape(t, [(height // 2) * (width // 2) * channels * batch_size, 4])\n",
        "\n",
        "    x1 = tf.transpose(bottom, perm=[0, 3, 1, 2])\n",
        "\n",
        "    values = tf.reshape(x1, [-1])\n",
        "\n",
        "    delta = tf.SparseTensor(indices, values, tf.to_int64(top_shape))\n",
        "\n",
        "    return tf.sparse_tensor_to_dense(tf.sparse_reorder(delta))\n",
        "\n",
        "\n",
        "#Función para realizar la operación de unpooling en una capa de 2x2, pero llena las áreas vacías con ceros.\n",
        "\n",
        "def UnPooling2x2ZeroFilled(x):\n",
        "    # https://github.com/tensorflow/tensorflow/issues/2169\n",
        "    out = tf.concat(3, [x, tf.zeros_like(x)])\n",
        "    out = tf.concat(2, [out, tf.zeros_like(out)])\n",
        "\n",
        "    sh = x.get_shape().as_list()\n",
        "    if None not in sh[1:]:\n",
        "        out_size = [-1, sh[1] * 2, sh[2] * 2, sh[3]]\n",
        "        return tf.reshape(out, out_size)\n",
        "    else:\n",
        "        shv = tf.shape(x)\n",
        "        ret = tf.reshape(out, tf.stack([-1, shv[1] * 2, shv[2] * 2, sh[3]]))\n",
        "        ret.set_shape([None, None, None, sh[3]])\n",
        "        return ret\n",
        "\n",
        "#FixedUnPooling (Función):Realiza una operación de unpooling utilizando una matriz fija para el producto de Kronecker.\n",
        "#Esta operación se utiliza para aumentar el tamaño de una capa en función de la entrada y la matriz de unpooling.\n",
        "#x: Un tensor NHWC (batch, height, width, channels).\n",
        "#shape: Entero o tupla (h, w) que especifica la forma deseada después del unpooling.\n",
        "#unpool_mat: Una matriz que se utiliza para el unpooling. Si es None, se utilizará una matriz con 1 en la esquina superior izquierda.\n",
        "\n",
        "def FixedUnPooling(x, shape, unpool_mat=None):\n",
        "    \"\"\"\n",
        "    Desagrupe la entrada con una matriz fija para realizar el producto Kronecker.\n",
        "    Argumentos:\n",
        "        x (tf.Tensor): un tensor NHWC\n",
        "        forma: int o (h, w) tupla\n",
        "        unpool_mat: una matriz 2D tf.Tensor o np.ndarray con tamaño = forma.\n",
        "            Si es Ninguno, se utilizará una matriz con 1 en la esquina superior izquierda.\n",
        "    Devoluciones:\n",
        "        tf.Tensor: un tensor NHWC.\n",
        "    \"\"\"\n",
        "    # shape = shape2d(shape)\n",
        "\n",
        "    # una implementación más rápida para este caso especial\n",
        "    if shape[0] == 2 and shape[1] == 2 and unpool_mat is None:\n",
        "        return UnPooling2x2ZeroFilled(x)\n",
        "\n",
        "    input_shape = x.get_shape().as_list()\n",
        "    if unpool_mat is None:\n",
        "        mat = np.zeros(shape, dtype='float32')\n",
        "        mat[0][0] = 1\n",
        "        unpool_mat = tf.constant(mat, name='unpool_mat')\n",
        "    elif isinstance(unpool_mat, np.ndarray):\n",
        "        unpool_mat = tf.constant(unpool_mat, name='unpool_mat')\n",
        "    assert unpool_mat.get_shape().as_list() == list(shape)\n",
        "\n",
        "    # realizar un producto de Kronecker de matriz tensorial\n",
        "    fx = flatten(tf.transpose(x, [0, 3, 1, 2]))\n",
        "    fx = tf.expand_dims(fx, -1)       # (bchw)x1\n",
        "    mat = tf.expand_dims(flatten(unpool_mat), 0)  # 1x(shxsw)\n",
        "    prod = tf.matmul(fx, mat)  # (bchw) x(shxsw)\n",
        "    prod = tf.reshape(prod, [-1, input_shape[3], input_shape[1], input_shape[2], shape[0], shape[1] ])\n",
        "    prod = tf.transpose(prod, [0, 2, 4, 3, 5, 1])\n",
        "    prod = tf.reshape(prod, [-1, input_shape[1] * shape[0], input_shape[2] * shape[1], input_shape[3] ])\n",
        "\n",
        "    return prod\n",
        "\n",
        "#flatten (Función):Aplana un tensor multidimensional en uno unidimensional.\n",
        "\n",
        "def flatten(x):\n",
        "    \"\"\"\n",
        "    Flatten the tensor.\n",
        "    \"\"\"\n",
        "    return tf.reshape(x, [-1])\n",
        "\n",
        "#binary_cross_entropy (Función):Calcula la entropía cruzada binaria entre dos tensores preds y targets.\n",
        "#Esta función se utiliza comúnmente para medir la pérdida en problemas de clasificación binaria.\n",
        "#preds: Tensor que contiene las predicciones.\n",
        "#targets: Tensor que contiene los valores objetivo.\n",
        "\n",
        "def binary_cross_entropy(preds, targets, name=None):\n",
        "    \"\"\"Computes binary cross entropy given `preds`.\n",
        "\n",
        "    For brevity, let `x = `, `z = targets`.  The logistic loss is\n",
        "\n",
        "        loss(x, z) = - sum_i (x[i] * log(z[i]) + (1 - x[i]) * log(1 - z[i]))\n",
        "\n",
        "    Args:\n",
        "        preds: A `Tensor` of type `float32` or `float64`.\n",
        "        targets: A `Tensor` of the same type and shape as `preds`.\n",
        "    \"\"\"\n",
        "    eps = 1e-12\n",
        "    with ops.op_scope([preds, targets], name, \"bce_loss\") as name:\n",
        "        preds = ops.convert_to_tensor(preds, name=\"preds\")\n",
        "        targets = ops.convert_to_tensor(targets, name=\"targets\")\n",
        "\n",
        "        return tf.reduce_mean(-(targets * tf.log(preds + eps) + (1. - targets) * tf.log(1. - preds + eps)))\n",
        "\n",
        "#conv_cond_concat (Función):Concatena una condición (un tensor y) en el eje de mapas de características de un tensor de entrada x.\n",
        "#Esto se utiliza comúnmente en GANs condicionales y otras aplicaciones donde se desea condicionar una capa en otra.\n",
        "\n",
        "\n",
        "def conv_cond_concat(x, y):\n",
        "    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n",
        "    x_shapes = x.get_shape()\n",
        "    y_shapes = y.get_shape()\n",
        "    return tf.concat(3, [x, y * tf.ones([x_shapes[0], x_shapes[1], x_shapes[2], y_shapes[3]])])\n",
        "\n",
        "#mse (Función):Calcula la pérdida de error cuadrático medio entre dos tensores pred y target.\n",
        "#Mide la diferencia media al cuadrado entre los valores previstos y los valores reales.\n",
        "\n",
        "def mse(pred, target):\n",
        "    num = pred.get_shape().as_list()[0]\n",
        "    pred = tf.reshape(pred, [num, -1])\n",
        "    target = tf.reshape(target, [num, -1])\n",
        "    mse_sum = tf.reduce_sum(tf.pow(tf.subtract(pred, target), 2.0), 1)\n",
        "    mse_loss = tf.reduce_mean(mse_sum)\n",
        "\n",
        "    return mse_loss\n",
        "\n",
        "#instance_norm (Función):Implementa la normalización de instancias en un tensor de entrada x.\n",
        "#La normalización de instancias se utiliza en arquitecturas de redes neuronales para mejorar la estabilidad del entrenamiento.\n",
        "\n",
        "def instance_norm(x, name):\n",
        "    with tf.variable_scope(name):\n",
        "        epsilon = 1e-5\n",
        "        mean, var = tf.nn.moments(x, [1, 2], keep_dims=True)\n",
        "        scale = tf.get_variable('scale', [x.get_shape()[-1]],\n",
        "                                initializer=tf.truncated_normal_initializer(mean=1.0, stddev=0.02))\n",
        "        offset = tf.get_variable('offset', [x.get_shape()[-1]], initializer=tf.constant_initializer(0.0))\n",
        "        out = scale * tf.div(x - mean, tf.sqrt(var + epsilon)) + offset\n",
        "\n",
        "    return out\n",
        "\n",
        "#l1_loss (Función):Calcula la pérdida de valor absoluto entre dos tensores pred y target.\n",
        "#Esta pérdida mide la diferencia absoluta media entre los valores previstos y los valores reales.\n",
        "\n",
        "def l1_loss(pred, target):\n",
        "    return tf.reduce_mean(tf.abs(pred - target))\n",
        "\n",
        "#l2_loss (Función):Calcula la pérdida de error cuadrático medio entre dos tensores pred y target. Similar a mse, pero sin el factor de 1/2.\n",
        "\n",
        "def l2_loss(pred, target):\n",
        "    return 1. / 2 * tf.reduce_mean(tf.pow(tf.subtract(pred, target), 2.0))\n",
        "\n",
        "#tv_loss (Función):Calcula la pérdida de variación total de una imagen o un conjunto de imágenes.\n",
        "#Esta pérdida se utiliza para promover la suavidad en las imágenes generadas y reducir el ruido.\n",
        "\n",
        "def tv_loss(images):\n",
        "    return tf.reduce_mean(tf.image.total_variation(images))\n",
        "\n",
        "#mmd_loss (Función):Calcula la pérdida de distancia máxima de la media entre dos conjuntos de datos (source y target).\n",
        "#Esta métrica se utiliza comúnmente en aplicaciones de dominio adversario para medir la diferencia entre distribuciones de datos.\n",
        "\n",
        "def mmd_loss(source, target):\n",
        "\n",
        "    source_mean = tf.reduce_mean(source)\n",
        "    target_mean = tf.reduce_mean(target)\n",
        "\n",
        "    mse_sum = tf.reduce_sum(tf.pow(tf.subtract(source_mean, target_mean), 2.0))*0.5\n",
        "\n",
        "    return mse_sum\n",
        "\n"
      ],
      "metadata": {
        "id": "GPu2iK4b43F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# source_input.py"
      ],
      "metadata": {
        "id": "zpbh2jJsRbJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "#from read_image import *\n",
        "from tensorflow.python.platform import gfile\n",
        "from tensorflow.python.platform import flags\n",
        "import numpy as np\n",
        "import scipy.io as scio\n",
        "from tensorflow.python.framework import ops\n",
        "from PIL import Image\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "T = 1\n",
        "IM_HEIGHT = 400\n",
        "IM_WIDTH = 400\n",
        "IM_CHANNELS = 3\n",
        "\n",
        "#_int64_feature y _bytes_feature: son funciones auxiliares utilizadas para convertir\n",
        "#datos en formatos que se pueden almacenar en archivos TFRecord, que es un formato de datos binarios utilizado en TensorFlow para almacenar datos.\n",
        "\n",
        "def _int64_feature(value):\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "#Lee imágenes desde un filename_queue usando tf.WholeFileReader() y decodifica la imagen.\n",
        "#La función acepta dos parámetros opcionales, new_height y new_width, que si se proporcionan, cambian el tamaño de la imagen usando tf.image.resize_images.\n",
        "#Las imágenes se normalizan mediante la resta de un valor constante de cada canal de color.\n",
        "\n",
        "def read_images(filename_queue, new_height=None, new_width=None):\n",
        "\n",
        "    reader = tf.WholeFileReader()\n",
        "    key, value = reader.read(filename_queue)\n",
        "    image = tf.image.decode_jpeg(value)  # use png or jpeg decoder based on your files\n",
        "    image = tf.reshape(image, [IM_HEIGHT, IM_WIDTH, IM_CHANNELS])\n",
        "\n",
        "    if new_height and new_width:\n",
        "        image = tf.image.resize_images(image, [new_height, new_width])\n",
        "\n",
        "    image = tf.cast(image, tf.float32) - np.array([104., 117., 124.])\n",
        "\n",
        "    return image\n",
        "\n",
        "#Función read_images2: Es similar a read_images, pero produce dos imágenes redimensionadas, una de 227x227 y otra de 128x128, ambas normalizadas.\n",
        "def read_images2(filename_queue):\n",
        "\n",
        "    reader = tf.WholeFileReader()\n",
        "    key, value = reader.read(filename_queue)\n",
        "    image = tf.image.decode_jpeg(value)  # use png or jpeg decoder based on your files\n",
        "    image = tf.reshape(image, [IM_HEIGHT, IM_WIDTH, IM_CHANNELS])\n",
        "\n",
        "    image_227 = tf.image.resize_images(image, [227, 227])\n",
        "    image_227 = tf.cast(image_227, tf.float32) - np.array([104., 117., 124.])\n",
        "\n",
        "    image_128 = tf.image.resize_images(image, [128, 128])\n",
        "    image_128 = tf.cast(image_128, tf.float32) - np.array([104., 117., 124.])\n",
        "\n",
        "    return image_227, image_128\n",
        "\n",
        "#Función read_images3: Lee imágenes y etiquetas desde un input_queue.\n",
        "#Lee el archivo y decodifica la imagen, define dos versiones redimensionadas de la imagen (227x227 y 128x128) y normaliza ambas.\n",
        "\n",
        "def read_images3(input_queue):\n",
        "\n",
        "    label = input_queue[1]\n",
        "    file_contents = tf.read_file(input_queue[0])\n",
        "    image = tf.image.decode_image(file_contents, channels=3)\n",
        "    image = tf.reshape(image, [IM_HEIGHT, IM_WIDTH, IM_CHANNELS])\n",
        "\n",
        "    image_227 = tf.image.resize_images(image, [227, 227])\n",
        "    image_227 = tf.cast(image_227, tf.float32) - np.array([104., 117., 124.])\n",
        "\n",
        "    image_128 = tf.image.resize_images(image, [128, 128])\n",
        "    # image_128 = tf.cast(image_128, tf.float32)\n",
        "    image_128 = tf.cast(image_128, tf.float32) - np.array([104., 117., 124.])\n",
        "\n",
        "    return image_227, image_128, label\n",
        "\n",
        "#Función load_source_batch: Lee una lista de nombres de archivos de imágenes y crea una cola de nombres de archivo usando tf.train.string_input_producer.\n",
        "#Usa la función read_images para leer y preprocesar las imágenes.\n",
        "#Usa tf.train.shuffle_batch para obtener un lote aleatorio de imágenes, configurando la capacidad del búfer y el número mínimo después de la reducción.\n",
        "\n",
        "def load_source_batch(filename, img_folder, batch_size, img_size, shuffle=True):\n",
        "    filenames = get_imgAndlabel_list(filename, img_folder)\n",
        "    print('%d images to train' %(len(filenames)))\n",
        "    if not filenames:\n",
        "        raise RuntimeError('No data files found.')\n",
        "\n",
        "    with tf.name_scope('input'):\n",
        "        filename_queue = tf.train.string_input_producer(filenames, shuffle=shuffle)\n",
        "\n",
        "        # Even when reading in multiple threads, share the filename queue.\n",
        "        image = read_images(filename_queue, new_height=img_size, new_width=img_size)\n",
        "        image_batch = tf.train.shuffle_batch(\n",
        "            [image],\n",
        "            batch_size=batch_size,\n",
        "            num_threads=4,\n",
        "            capacity=1280,\n",
        "            min_after_dequeue=640)\n",
        "        # image_batch = tf.train.batch(\n",
        "        #     [image],\n",
        "        #     batch_size=batch_size,\n",
        "        #     num_threads=4,\n",
        "        #     capacity=1280)\n",
        "        #\n",
        "        return image_batch\n",
        "\n",
        "\n",
        "#Función load_source_batch2: Lee la lista de nombres de imágenes y etiquetas.\n",
        "#Configura una cola de nombres de archivo usando tf.train.string_input_producer.\n",
        "#Lee imágenes redimensionadas de 227x227 y 128x128 usando read_images2.\n",
        "#Usa tf.train.shuffle_batch para obtener lotes aleatorios de las imágenes redimensionadas.\n",
        "\n",
        "def load_source_batch2(filename, img_folder, batch_size, shuffle=True):\n",
        "\n",
        "    filenames = get_imgAndlabel_list(filename, img_folder)\n",
        "    print('%d images to train' % (len(filenames)))\n",
        "    if not filenames:\n",
        "        raise RuntimeError('No data files found.')\n",
        "\n",
        "    with tf.name_scope('input'):\n",
        "        filename_queue = tf.train.string_input_producer(filenames, shuffle=shuffle)\n",
        "\n",
        "        # Incluso cuando lea en varios hilos, comparta el nombre del archivo queue.\n",
        "        image_227, image_128 = read_images2(filename_queue)\n",
        "        image_227_batch, image_128_batch = tf.train.shuffle_batch(\n",
        "            [image_227, image_128],\n",
        "            batch_size=batch_size,\n",
        "            num_threads=4,\n",
        "            capacity=1280,\n",
        "            min_after_dequeue=640)\n",
        "\n",
        "        return image_227_batch, image_128_batch\n",
        "\n",
        "#Función load_source_batch3: Obtiene listas de nombres de imágenes y etiquetas.\n",
        "#Convierte las listas en tensores usando tf.convert_to_tensor.\n",
        "#Crea una cola de entrada con imágenes y etiquetas usando tf.train.slice_input_producer.\n",
        "#Lee imágenes redimensionadas de 227x227 y 128x128 y etiquetas usando read_images3.\n",
        "#Usa tf.train.shuffle_batch para obtener lotes aleatorios de las imágenes redimensionadas y las etiquetas.\n",
        "\n",
        "def load_source_batch3(filename, img_folder, batch_size, shuffle=True):\n",
        "\n",
        "    img_list, label_list = get_imgAndlabel_list2(filename, img_folder)\n",
        "    print('%d images to train' % (len(img_list)))\n",
        "\n",
        "    images = ops.convert_to_tensor(img_list, dtype=tf.string)\n",
        "    labels = ops.convert_to_tensor(label_list, dtype=tf.int32)\n",
        "\n",
        "    # Hace una cola de entrada\n",
        "    input_queue = tf.train.slice_input_producer([images, labels], shuffle=shuffle)\n",
        "\n",
        "    # Incluso cuando lea en varios hilos, comparta el nombre del archivo queue.\n",
        "    image_227, image_128, label = read_images3(input_queue)\n",
        "    image_227_batch, image_128_batch, label_batch = tf.train.shuffle_batch(\n",
        "        [image_227, image_128, label],\n",
        "        batch_size=batch_size,\n",
        "        num_threads=4,\n",
        "        capacity=1280,\n",
        "        min_after_dequeue=640)\n",
        "\n",
        "    return image_227_batch, image_128_batch, label_batch\n",
        "\n",
        "#get_imgAndlabel_list: Lee un archivo que contiene nombres de imágenes y etiquetas.\n",
        "#Recibe de entrada:\n",
        "#filename: Ruta al archivo que contiene los nombres de las imágenes y las etiquetas.\n",
        "#img_folder: Ruta de la carpeta que contiene las imágenes.\n",
        "#Salida:Lista de nombres de imágenes: imgname_lists.\n",
        "#Esta función abre el archivo filename, lee sus líneas y cierra el archivo después de la lectura. Itera sobre las líneas, divide cada línea en dos partes\n",
        "#(el nombre de la imagen y la etiqueta separados por espacio), luego agrega la ruta completa de la imagen al img_folder a la lista imgname_lists.\n",
        "\n",
        "def get_imgAndlabel_list(filename, img_folder):\n",
        "    \"\"\"\n",
        "    :nombre de archivo del parámetro:\n",
        "    cada línea en el nombre del archivo es img_name \\space label\n",
        "    :devolver:\n",
        "    lista de nombres img\n",
        "    lista de etiquetas\n",
        "    \"\"\"\n",
        "    f = open(filename, 'r')\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "    imgname_lists = []\n",
        "    for i in range(len(lines)):\n",
        "        img_name = lines[i].split()[0]\n",
        "        imgname_lists.append(os.path.join(img_folder, img_name))\n",
        "    return imgname_lists\n",
        "\n",
        "\n",
        "#get_imgAndlabel_list2: Lee un archivo que contiene nombres de imágenes y etiquetas, procesarlos y almacenarlos en listas separadas.\n",
        "#Recibe de entrada:\n",
        "#filename: Ruta al archivo que contiene los nombres de las imágenes y las etiquetas.\n",
        "#img_folder: Ruta de la carpeta que contiene las imágenes.\n",
        "#Salida:\n",
        "#Lista de nombres de imágenes: imgname_lists.\n",
        "#Lista de etiquetas como enteros: label_lists.\n",
        "#Esta función hace lo mismo que get_imgAndlabel_list,\n",
        "#pero además de obtener los nombres de las imágenes, también convierte las etiquetas en enteros y las almacena en la lista label_lists.\n",
        "\n",
        "def get_imgAndlabel_list2(filename, img_folder):\n",
        "    \"\"\"\n",
        "    :nombre de archivo del parámetro:\n",
        "    cada línea en el nombre del archivo es img_name \\space label\n",
        "    :devolver:\n",
        "    lista de nombres img\n",
        "    lista de etiquetas\n",
        "    \"\"\"\n",
        "    f = open(filename, 'r')\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "    imgname_lists = []\n",
        "    label_lists = []\n",
        "    for i in range(len(lines)):\n",
        "        img_name, label = lines[i].split()\n",
        "        imgname_lists.append(os.path.join(img_folder, img_name))\n",
        "        label_lists.append(int(label))\n",
        "\n",
        "    return imgname_lists, label_lists"
      ],
      "metadata": {
        "id": "tXo7A_MK5BDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "N1cP8cIqRkgq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utils.py"
      ],
      "metadata": {
        "id": "x4raIBuKSCDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install scipy==1.11.3"
      ],
      "metadata": {
        "id": "EFTGx6FSNQpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install lightgbm==2.2.3\n",
        "import matplotlib.pyplot as plt\n",
        "from __future__ import division\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "import pprint\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from time import gmtime, strftime\n",
        "import cv2\n",
        "from imageio import imsave\n",
        "\n",
        "#Función: get_image(image_path, image_size, is_crop=True, resize_w=64, is_grayscale=False):\n",
        "#Carga una imagen del archivo y la transforma según ciertos parámetros como recorte,tamaño y escala de grises.\n",
        "\n",
        "def get_image(image_path, image_size, is_crop=True, resize_w=64, is_grayscale = False):\n",
        "    return transform(imread(image_path, is_grayscale), image_size, is_crop, resize_w)\n",
        "\n",
        "#Fución save_images(images, size, image_path): Guarda un conjunto de imágenes.\n",
        "\n",
        "def save_images(image, size, image_path):\n",
        "    # Expand the dimensions of the image to create a batch.\n",
        "    # image = np.expand_dims(image, axis=0)\n",
        "    return imsave(inverse_transform(image), size, image_path)\n",
        "\n",
        "#Función save_images2(images, size, image_path): función para guardar imágenes.\n",
        "\n",
        "def save_images2(images, size, image_path):\n",
        "    return imsave(images, size, image_path)\n",
        "\n",
        "# Función imread(path, is_grayscale=False): Lee una imagen desde un archivo y la convierte en una matriz NumPy.\n",
        "def imread(path, is_grayscale = False):\n",
        "    if (is_grayscale):\n",
        "        return scipy.misc.imread(path, flatten = True).astype(np.float)\n",
        "    else:\n",
        "        return scipy.misc.imread(path).astype(np.float)\n",
        "\n",
        "#Función save_source se encarga de guardar un conjunto de imágenes en un archivo en una ruta especificada\n",
        "#img = merge(images, size): Combina las imágenes en una sola imagen grande utilizando la función merge.\n",
        "#mean = np.array([104., 117., 124.]): Define un vector que representa la media de los valores de píxeles para normalizar la imagen. Estos valores son típicamente usados en la etapa de preprocesamiento o posprocesamiento de imágenes en modelos pre-entrenados o durante la transferencia de aprendizaje.\n",
        "#img = np.uint8(img + mean): Se suma este vector de media a la imagen combinada.\n",
        "#El propósito de esta suma es deshacer una normalización previa antes de guardar la imagen.\n",
        "\n",
        "\n",
        "def save_source(images, size, path):\n",
        "    img = merge(images, size)\n",
        "    mean = np.array([104., 117., 124.])\n",
        "    img = np.uint8(img + mean)\n",
        "    #plt.figure()\n",
        "    #plt.imshow(img)\n",
        "    #plt.show()\n",
        "    #print(img)\n",
        "    #cv2.imwrite(path, img[:, :, [2, 1, 0]])\n",
        "\n",
        "# Función merge_images(images, size): Combina imágenes en una sola imagen grande.\n",
        "\n",
        "def merge_images(images, size):\n",
        "    return inverse_transform(images)\n",
        "\n",
        "# Función merge(images, size): Función para combinar imágenes en una cuadrícula grande para visualización o almacenamiento.\n",
        "def merge(images, size):\n",
        "    print(images.shape)\n",
        "    h, w = images.shape[1], images.shape[2]\n",
        "    #print(h * size[0], w * size[1])\n",
        "    img = np.zeros((h * size[0], w * size[1], 3),dtype=np.uint8)\n",
        "    for idx, image in enumerate(images):\n",
        "        i = idx % size[1]\n",
        "        j = idx // size[1]\n",
        "        image = cv2.normalize(image, dst=None, alpha=0, beta=255,norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "\n",
        "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
        "    #print(image)\n",
        "    #plt.figure()\n",
        "    #plt.imshow(img)\n",
        "    #plt.show()\n",
        "\n",
        "    #print(img.shape)\n",
        "\n",
        "    return img\n",
        "\n",
        "#Función imsave(images, size, path): Guarda un conjunto de imágenes combinadas.\n",
        "\n",
        "def imsave(images, size, path):\n",
        "    return imageio.imsave(path, merge(images, size)) #CAMBIO\n",
        "\n",
        "#Función center_crop(x, crop_h, crop_w=None, resize_w=64): Recorta una imagen alrededor de su centro.\n",
        "\n",
        "def center_crop(x, crop_h, crop_w=None, resize_w=64):\n",
        "    if crop_w is None:\n",
        "        crop_w = crop_h\n",
        "    h, w = x.shape[:2]\n",
        "    j = int(round((h - crop_h)/2.))\n",
        "    i = int(round((w - crop_w)/2.))\n",
        "    return scipy.misc.imresize(x[j:j+crop_h, i:i+crop_w],\n",
        "                               [resize_w, resize_w])\n",
        "\n",
        "#Función transform(image, npx=64, is_crop=True, resize_w=64): Realiza una transformación en la imagen para normalizar sus valores en el rango [-1, 1].\n",
        "\n",
        "def transform(image, npx=64, is_crop=True, resize_w=64):\n",
        "    #npx: # de píxeles de ancho/alto de la imagen\n",
        "    if is_crop:\n",
        "        cropped_image = center_crop(image, npx, resize_w=resize_w)\n",
        "    else:\n",
        "        cropped_image = image\n",
        "    return np.array(cropped_image)/127.5 - 1.\n",
        "\n",
        "#Función inverse_transform(images): Invierte la transformación aplicada a las imágenes para regresar al rango [0, 1].\n",
        "\n",
        "def inverse_transform(images):\n",
        "    return (images+1.)/2.\n"
      ],
      "metadata": {
        "id": "3SVoePYL6YD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CODIGOS PRINCIPALES"
      ],
      "metadata": {
        "id": "Sz1O_-lcTTgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# models.py"
      ],
      "metadata": {
        "id": "4ng97C0_UPSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os.path\n",
        "import random\n",
        "from tensorflow.python.training import moving_averages\n",
        "import sys\n",
        "sys.path.append('./tools/')\n",
        "#from ops import *\n",
        "\n",
        "#Resumen:proporciona un esquema de red neuronal convolucional específico para la tarea de envejecimiento facial,\n",
        "#adaptando la arquitectura de AlexNet para cumplir con los requisitos de la tarea de predicción de edad.\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#Método __init__, se definen varios parámetros y configuraciones para el modelo,\n",
        "#como la sesión de TensorFlow (sess), la tasa de aprendizaje (lr), la probabilidad de retención (keep_prob).\n",
        "#Estos parámetros controlan aspectos como el peso de la pérdida GAN, la pérdida de características,\n",
        "#la pérdida de edad, el peso de la pérdida de regularización total variacional, entre otros.\n",
        "\n",
        "class FaceAging(object):\n",
        "    def __init__(self, sess, lr, keep_prob, model_num, batch_size=64, decay_steps=None,\n",
        "                 gan_loss_weight=None, fea_loss_weight=None, age_loss_weight=None,\n",
        "                 tv_loss_weight=None):\n",
        "\n",
        "        self.sess = sess\n",
        "        self.NUM_CLASSES = 2000\n",
        "        self.KEEP_PROB = keep_prob\n",
        "        self.train_layers = ['conv1', 'conv2', 'conv3', 'conv4', 'conv5', 'fc6', 'fc7']\n",
        "        self.skip_layers = ['fc8']\n",
        "        self.learning_rate = lr\n",
        "        self.decay_steps = decay_steps\n",
        "        self.learning_rate_decay_factor = 0.1\n",
        "        self.model_num = model_num\n",
        "        self._extra_train_ops = []\n",
        "        self.batch_size = batch_size\n",
        "        self.mean = tf.constant([104., 117., 124.])\n",
        "        self.fea_loss_weight = fea_loss_weight\n",
        "        self.age_loss_weight = age_loss_weight\n",
        "        self.gan_loss_weight = gan_loss_weight\n",
        "        self.tv_loss_weight = tv_loss_weight\n",
        "        self.weight_decay_rate = 0.0005\n",
        "\n",
        "#Método inference: Este método define la arquitectura de la red neuronal convolucional.\n",
        "#Utiliza la arquitectura de AlexNet adaptada a las necesidades del problema de envejecimiento facial.\n",
        "#Resumen de las capas y operaciones:\n",
        "#Capas convolucionales (conv1, conv2, conv3, conv4, conv5) seguidas de capas de agrupación (pool1, pool2, pool5) y capas de normalización local (norm1, norm2).\n",
        "#Las capas totalmente conectadas (fc6, fc7, fc8) realizan operaciones de convolución con todas las neuronas en una capa conectadas a todas las neuronas en la capa siguiente.\n",
        "#Estas capas están seguidas por capas de abandono (dropout6, dropout7) para regularizar el modelo y evitar el sobreajuste.\n",
        "#La capa fc8 produce las activaciones sin escala, que generalmente se utilizan para calcular la entropía cruzada en la función de pérdida.\n",
        "\n",
        "    def inference(self, x, scope_name='alexnet', reuse=False):\n",
        "        with tf.variable_scope(scope_name, reuse=reuse) as scope:\n",
        "            # Primera capa: Conv (w ReLu) -> Pool -> Lrn\n",
        "            conv1 = conv(x, 11, 11, 96, 4, 4, padding='VALID', name='conv1')\n",
        "            pool1 = max_pool(conv1, 3, 3, 2, 2, padding='VALID', name='pool1')\n",
        "            norm1 = lrn(pool1, 2, 2e-05, 0.75, name='norm1')\n",
        "\n",
        "            # Segunda Capa: Conv (w ReLu) -> Pool -> Lrn with 2 groups\n",
        "            conv2 = conv(norm1, 5, 5, 256, 1, 1, groups=2, name='conv2')\n",
        "            pool2 = max_pool(conv2, 3, 3, 2, 2, padding='VALID', name='pool2')\n",
        "            norm2 = lrn(pool2, 2, 2e-05, 0.75, name='norm2')\n",
        "\n",
        "            # Tercera Capa: Conv (w ReLu)\n",
        "            conv3 = conv(norm2, 3, 3, 384, 1, 1, name='conv3')\n",
        "\n",
        "            # Cuarta Capa: Conv (w ReLu) splitted into two groups\n",
        "            conv4 = conv(conv3, 3, 3, 384, 1, 1, groups=2, name='conv4')\n",
        "\n",
        "            # Quinta Capa: Conv (w ReLu) -> Pool splitted into two groups\n",
        "            conv5 = conv(conv4, 3, 3, 256, 1, 1, groups=2, name='conv5')\n",
        "            pool5 = max_pool(conv5, 3, 3, 2, 2, padding='VALID', name='pool5')\n",
        "\n",
        "            # Sexta Capa: Flatten -> FC (w ReLu) -> Dropout\n",
        "            flattened = tf.reshape(pool5, [-1, 6 * 6 * 256])\n",
        "            fc6 = fc(flattened, 6 * 6 * 256, 4096, name='fc6')\n",
        "            dropout6 = dropout(fc6, self.KEEP_PROB)\n",
        "\n",
        "            # Septima Capa: FC (w ReLu) -> Dropout\n",
        "            fc7 = fc(dropout6, 4096, 4096, name='fc7')\n",
        "            dropout7 = dropout(fc7, self.KEEP_PROB)\n",
        "            # Octava Capa: FC and return unscaled activations (for tf.nn.softmax_cross_entropy_with_logits)\n",
        "            self.fc8 = fc(dropout7, 4096, self.NUM_CLASSES, relu=False, name='fc8')\n",
        "\n",
        "            return scope\n",
        "\n",
        "\n",
        "#Método face_age_alexnet: define una red neuronal convolucional basada en la arquitectura AlexNet adaptada para el reconocimiento de edad facial.\n",
        "#Descripción:\n",
        "#Capas convolucionales y de agrupamiento: El método comienza con capas convolucionales (conv1, conv2, conv3, conv4, conv5) seguidas de capas de agrupamiento (pool1, pool2, pool5).\n",
        "#Capas totalmente conectadas y de abandono: Luego, hay capas totalmente conectadas (fc6, fc7) seguidas de capas de abandono (dropout6, dropout7) para regularizar el modelo.\n",
        "#Capas adicionales para la tarea de edad: Si if_age es verdadero, se agregan capas adicionales (age_fc6, age_fc7, age_logits) específicamente para la tarea de clasificación de edad.\n",
        "\n",
        "\n",
        "    def face_age_alexnet(self, x, scope_name='alexnet', if_age=False, reuse=False):\n",
        "        with tf.variable_scope(scope_name, reuse=reuse) as scope:\n",
        "            # Primera Capa: Conv (w ReLu) -> Pool -> Lrn\n",
        "            conv1 = conv(x, 11, 11, 96, 4, 4, padding='VALID', name='conv1')\n",
        "            pool1 = max_pool(conv1, 3, 3, 2, 2, padding='VALID', name='pool1')\n",
        "            norm1 = lrn(pool1, 2, 2e-05, 0.75, name='norm1')\n",
        "\n",
        "            # Segunda Capa: Conv (w ReLu) -> Pool -> Lrn with 2 groups\n",
        "            conv2 = conv(norm1, 5, 5, 256, 1, 1, groups=2, name='conv2')\n",
        "            pool2 = max_pool(conv2, 3, 3, 2, 2, padding='VALID', name='pool2')\n",
        "            norm2 = lrn(pool2, 2, 2e-05, 0.75, name='norm2')\n",
        "\n",
        "            # Tercera Capa: Conv (w ReLu)\n",
        "            conv3 = conv(norm2, 3, 3, 384, 1, 1, name='conv3')\n",
        "            self.conv3 = conv3\n",
        "            # Cuarta Capa: Conv (w ReLu) splitted into two groups\n",
        "            conv4 = conv(conv3, 3, 3, 384, 1, 1, groups=2, name='conv4')\n",
        "            self.conv4 = conv4\n",
        "\n",
        "            # Quinta Capa: Conv (w ReLu) -> Pool splitted into two groups\n",
        "            conv5 = conv(conv4, 3, 3, 256, 1, 1, groups=2, name='conv5')\n",
        "            self.conv5 = conv5\n",
        "\n",
        "            pool5 = max_pool(conv5, 3, 3, 2, 2, padding='VALID', name='pool5')\n",
        "            self.pool5 = pool5\n",
        "\n",
        "            # Sexta Capa: Flatten -> FC (w ReLu) -> Dropout\n",
        "            flattened = tf.reshape(pool5, [-1, 6 * 6 * 256])\n",
        "            fc6 = fc(flattened, 6 * 6 * 256, 4096, name='fc6')\n",
        "            self.fc6 = fc6\n",
        "            dropout6 = dropout(fc6, self.KEEP_PROB)\n",
        "\n",
        "            # Septima Capa: FC (w ReLu) -> Dropout\n",
        "            fc7 = fc(dropout6, 4096, 4096, name='fc7')\n",
        "            self.fc7 = fc7\n",
        "            dropout7 = dropout(fc7, self.KEEP_PROB)\n",
        "\n",
        "            face_fc9 = fc(dropout7, 4096, 256, name='new_1')\n",
        "            self.fc9 = face_fc9\n",
        "            # Octava Capa: FC y activaciones de retorno sin escala (for tf.nn.softmax_cross_entropy_with_logits)\n",
        "            self.face_logits = fc(face_fc9, 256, self.NUM_CLASSES, relu=False, name='new_2')\n",
        "\n",
        "            if if_age:\n",
        "                age_fc6 = fc(flattened, 6 * 6 * 256, 4096, name='age_fc6')\n",
        "                age_dropout6 = dropout(age_fc6, self.KEEP_PROB)\n",
        "                # 7th Capa: FC (w ReLu) -> Dropout\n",
        "                age_fc7 = fc(age_dropout6, 4096, 4096, name='age_fc7')\n",
        "                age_dropout7 = dropout(age_fc7, self.KEEP_PROB)\n",
        "                self.age_logits = fc(age_dropout7, 4096, 5, name='age_fc8', relu=False)\n",
        "\n",
        "            return scope\n",
        "\n",
        "#Método ResnetGenerator: Este método implementa un generador de la arquitectura de red residual (ResNet) para tareas de generación de imágenes.\n",
        "#Descripción:\n",
        "#Construcción de la red residual: Define capas convolucionales, funciones de activación ReLU y capas de normalización de lotes para crear una estructura de red residual.\n",
        "#Bucles de unidades residuales: Utiliza bucles para construir múltiples unidades residuales dentro de la red.\n",
        "#Capas de convolución transpuesta: Utiliza capas de convolución transpuesta (deconvolución) para aumentar el tamaño de las características.\n",
        "#Generación de imagen: Retorna una imagen generada por la red como salida final, normalizada mediante la función de activación tangente hiperbólica.\n",
        "\n",
        "\n",
        "    def ResnetGenerator(self, image, name, n_blocks=6, condition=None, mode='train', reuse=False):\n",
        "        with tf.variable_scope(name):\n",
        "            if reuse:\n",
        "                tf.get_variable_scope().reuse_variables()\n",
        "\n",
        "            if condition is not None:\n",
        "                image = tf.concat([image, condition], axis=3)\n",
        "\n",
        "            x = tf.nn.relu(self.batch_norm('bn1', conv2d(image, 32, 7, 7, d_h=1, d_w=1, name='conv1'), mode=mode))\n",
        "            x = tf.nn.relu(self.batch_norm('bn2', conv2d(x, 64, 3, 3,  name='conv2'), mode=mode))\n",
        "\n",
        "            # if condition is not None:\n",
        "                # x = tf.concat([x, condition], axis=3)\n",
        "\n",
        "            x = tf.nn.relu(self.batch_norm('bn3', conv2d(x, 128, 3, 3, name='conv3'), mode=mode))\n",
        "\n",
        "            for i in range(n_blocks):\n",
        "                with tf.variable_scope('unit_%d' % i):\n",
        "                    x = self.residual(x, 3, 128)\n",
        "\n",
        "            x_shape = x.get_shape().as_list()\n",
        "            x = deconv2d(x, [x_shape[0], x_shape[1]*2, x_shape[1]*2, 64], 3, 3, name=\"deconv1\")\n",
        "            x = tf.nn.relu(self.batch_norm('bn4', x, mode=mode))\n",
        "\n",
        "            x_shape = x.get_shape().as_list()\n",
        "            x = deconv2d(x, [x_shape[0], x_shape[1]*2, x_shape[1]*2, 32], 3, 3, name=\"deconv2\")\n",
        "            x = tf.nn.relu(self.batch_norm('bn5', x, mode=mode))\n",
        "\n",
        "            x = conv2d(x, 3, 7, 7, d_h=1, d_w=1, name='conv4')\n",
        "            print(x.get_shape)\n",
        "\n",
        "            return tf.nn.tanh(x)\n",
        "\n",
        "#Método PatchDiscriminator: Este método implementa un discriminador de la red neuronal, específicamente diseñado para la arquitectura PatchGAN.\n",
        "#Arquitectura de la red consta de:\n",
        "#Capas convolucionales: Se utilizan varias capas convolucionales (conv2d) con activaciones de Leaky ReLU (lrelu) y capas de normalización por lotes (batch_norm) intercaladas.\n",
        "#Integración de condiciones: La red también puede considerar una condición adicional, concatenando la condición con las características de la imagen antes de algunas capas convolucionales.\n",
        "\n",
        "\n",
        "    def PatchDiscriminator(self, image, name, condition=None, mode='train', reuse=False):\n",
        "        with tf.variable_scope(name):\n",
        "            if reuse:\n",
        "                tf.get_variable_scope().reuse_variables()\n",
        "\n",
        "            x = lrelu(conv2d(image, 64, 4, 4, name='dis'))\n",
        "            if condition is not None:\n",
        "                x = tf.concat([x, condition], axis=3)\n",
        "\n",
        "            x = lrelu(self.batch_norm('dis_bn0', conv2d(x, 128, 4, 4, name='dis_1'), mode=mode))\n",
        "\n",
        "            x = lrelu(self.batch_norm('dis_bn1', conv2d(x, 256, 4, 4, name='dis_2'), mode=mode))\n",
        "\n",
        "            x = lrelu(self.batch_norm('dis_bn2', conv2d(x, 512, 4, 4, d_h=1, d_w=1, name='dis_3'), mode=mode))\n",
        "\n",
        "            x = conv2d(x, 512, 4, 4, d_h=1, d_w=1, name='dis_4')\n",
        "\n",
        "            print(x.get_shape())\n",
        "\n",
        "            return x\n",
        "\n",
        "#Método train_age_lsgan_transfer: Este método realiza el entrenamiento del modelo.\n",
        "#Descripción general:\n",
        "#Preparación de las características de entrada: Se extraen las características de la red face_age_alexnet para su uso posterior.\n",
        "#Generación de imágenes falsas: Se genera una imagen falsa usando un generador (ResnetGenerator) con las características extraídas.\n",
        "#Evaluación del discriminador: Se alimentan imágenes reales con etiquetas falsas, imágenes reales con etiquetas reales y la imagen falsa generada con etiquetas reales al discriminador para evaluar pérdidas de adversario (d_loss y g_loss).\n",
        "#Cálculo de pérdidas: Se calculan diversas pérdidas, incluyendo pérdida de adversario, pérdida de edad (age_loss) y pérdida de características (fea_loss).\n",
        "#Optimización: Se define el optimizador (AdamOptimizer) para minimizar las pérdidas calculadas y se ejecuta la optimización.\n",
        "\n",
        "\n",
        "    # lsgan condicional + norma por lotes\n",
        "    def train_age_lsgan_transfer(self, source_img_227, source_img_128, imgs, true_label_fea_128, true_label_fea_64,\n",
        "                                 false_label_fea_64, fea_layer_name, age_label):\n",
        "        \"\"\"\n",
        "        :param source_img_227: remove mean and size is 227\n",
        "        :param source_img_128: remove mean and size is 128\n",
        "        :param imgs: range in [-1, 1]\n",
        "        :param true_label_fea: the same size as imgs, has 5 channes\n",
        "        :param false_label_fea: the same size as imgs, has 5 channels\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        self.face_age_alexnet(source_img_227, if_age=True)\n",
        "        if fea_layer_name == 'conv3':\n",
        "            source_fea = self.conv3\n",
        "        elif fea_layer_name == 'conv4':\n",
        "            source_fea = self.conv4\n",
        "        elif fea_layer_name == 'conv5':\n",
        "            source_fea = self.conv5\n",
        "        elif fea_layer_name == 'pool5':\n",
        "            source_fea = self.pool5\n",
        "        elif fea_layer_name == 'fc6':\n",
        "            source_fea = self.fc6\n",
        "        elif fea_layer_name == 'fc7':\n",
        "            source_fea = self.fc7\n",
        "\n",
        "        self.g_source = self.ResnetGenerator(source_img_128, name='generator', condition=true_label_fea_128)\n",
        "\n",
        "        discriminator = self.PatchDiscriminator\n",
        "\n",
        "        # real image, right label\n",
        "        D1_logits = discriminator(imgs, name='discriminator', condition=true_label_fea_64)\n",
        "        # real image, false label\n",
        "        D2_logits = discriminator(imgs, name='discriminator', condition=false_label_fea_64, reuse=True)\n",
        "        # fake image, true label\n",
        "        D3_logits = discriminator(self.g_source, name='discriminator', condition=true_label_fea_64, reuse=True)\n",
        "\n",
        "        d_loss_real = tf.reduce_mean(tf.square(D1_logits - 1.))\n",
        "        d_loss_fake1 = tf.reduce_mean(tf.square(D2_logits))\n",
        "        d_loss_fake2 = tf.reduce_mean(tf.square(D3_logits))\n",
        "\n",
        "        self.d_loss = (1. / 2 * (d_loss_real + 1. / 2 * (d_loss_fake1 + d_loss_fake2))) * self.gan_loss_weight\n",
        "\n",
        "        self.g_loss = (1. / 2 * tf.reduce_mean(tf.square(D3_logits - 1.))) * self.gan_loss_weight\n",
        "\n",
        "        g_source = (self.g_source + 1.) * 127.5\n",
        "        # self.tv_loss = total_variation_loss(g_source) * self.tv_loss_weight\n",
        "\n",
        "        g_source = tf.image.resize_bilinear(images=g_source, size=[227, 227])\n",
        "        g_source = g_source - self.mean\n",
        "\n",
        "        self.face_age_alexnet(g_source, if_age=True, reuse=True)\n",
        "        self.age_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "                                                logits=self.age_logits, labels=age_label)) * self.age_loss_weight\n",
        "\n",
        "        if fea_layer_name == 'conv3':\n",
        "            ge_fea = self.conv3\n",
        "        elif fea_layer_name == 'conv4':\n",
        "            ge_fea = self.conv4\n",
        "        elif fea_layer_name == 'conv5':\n",
        "            ge_fea = self.conv5\n",
        "        elif fea_layer_name == 'pool5':\n",
        "            ge_fea = self.pool5\n",
        "        elif fea_layer_name == 'fc6':\n",
        "            ge_fea = self.fc6\n",
        "        elif fea_layer_name == 'fc7':\n",
        "            ge_fea = self.fc7\n",
        "\n",
        "        self.fea_loss = self.fea_loss_weight * mse(ge_fea, source_fea)\n",
        "\n",
        "        g_loss = self.g_loss + self.fea_loss + self.age_loss\n",
        "\n",
        "        self.get_vars()\n",
        "\n",
        "        d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=0.5).minimize(self.d_loss,\n",
        "                                                                                 var_list=self.d_vars)\n",
        "        train_ops = [d_optim] + self._extra_train_ops\n",
        "        self.d_optim = tf.group(*train_ops)\n",
        "\n",
        "        g_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=0.5).minimize(g_loss, var_list=self.g_vars)\n",
        "        train_ops = [g_optim] + self._extra_train_ops\n",
        "        self.g_optim = tf.group(*train_ops)\n",
        "\n",
        "\n",
        "\n",
        "#Método generate_images: Este método utiliza el generador (ResnetGenerator) para generar imágenes a partir de una imagen de entrada y características específicas.\n",
        "#Esta función se utiliza durante el entrenamiento para generar imágenes falsas y también puede usarse para generar imágenes en modo de prueba.\n",
        "\n",
        "    def generate_images(self, source_img_128, true_label_fea, stable_bn=False, reuse=False, mode='test'):\n",
        "\n",
        "        g_source = self.ResnetGenerator(source_img_128, name='generator', condition=true_label_fea,\n",
        "                                             mode=mode, reuse=reuse)\n",
        "        if stable_bn:\n",
        "            train_ops = self._extra_train_ops\n",
        "            self.optim = tf.group(*train_ops)\n",
        "        # self.get_vars()\n",
        "\n",
        "        return g_source\n",
        "\n",
        "#Esta función define una unidad residual. Toma una entrada x, aplica dos capas convolucionales seguidas de normalización por lotes y,\n",
        "#realiza una operación de suma con la entrada original.\n",
        "#Descripción:\n",
        "#Capas Convolucionales: Se utilizan dos capas convolucionales (conv2d) con las dimensiones filter_width y out_channels.\n",
        "#Normalización por Lotes: Entre cada capa convolucional, se aplica la normalización por lotes (batch_norm) que normaliza los datos antes de pasarlos a las capas convolucionales siguientes.\n",
        "#Conexión Residual: La operación x += orig_x agrega la entrada original a la salida de las capas convolucionales y normalización por lotes. Esto crea la conexión residual.\n",
        "\n",
        "    def residual(self, x, filter_width, out_channels, mode='train'):\n",
        "        \"\"\"Residual unit with 2 sub layers.\"\"\"\n",
        "        in_channels = x.get_shape().as_list()\n",
        "        in_channels = in_channels[-1]\n",
        "        orig_x = x\n",
        "\n",
        "        with tf.variable_scope('sub1'):\n",
        "            x = conv2d(x, out_channels, filter_width, filter_width, d_h=1, d_w=1,  name='conv1')\n",
        "            x = self.batch_norm('bn1', x, mode=mode)\n",
        "            x = tf.nn.relu(x)\n",
        "\n",
        "        with tf.variable_scope('sub2'):\n",
        "            x = conv2d(x, out_channels, filter_width, filter_width, d_h=1, d_w=1, name='conv2')\n",
        "            x = self.batch_norm('bn2', x, mode=mode)\n",
        "\n",
        "\n",
        "        with tf.variable_scope('sub_add'):\n",
        "            if in_channels != out_channels:\n",
        "                orig_x = tf.pad(orig_x, [[0, 0], [0, 0],  [(out_channels - in_channels) // 2, (out_channels - in_channels) // 2]])\n",
        "            x += orig_x\n",
        "\n",
        "        return x\n",
        "\n",
        "#Esta función realiza la normalización por lotes. Calcula la media y la varianza a lo largo de los ejes espaciales (ancho, alto y canal) para normalizar la entrada x.\n",
        "#Si el modo es \"train\", se calculan y actualizan las estadísticas en ejecución para su uso posterior.\n",
        "#Si el modo es diferente, se utilizan las estadísticas en ejecución:\n",
        "#Parámetros Trainables: Se crean y utilizan los parámetros beta y gamma para la normalización por lotes.\n",
        "#Cálculo de Momentos: Calcula la media y la varianza si está en el modo de entrenamiento. En otro caso, utiliza los valores en ejecución.\n",
        "#Normalización: Aplica la normalización por lotes a la entrada x utilizando las estadísticas calculadas.\n",
        "\n",
        "    # TODO(xpan): Consider batch_norm in contrib/layers/python/layers/layers.py\n",
        "    def batch_norm(self, name, x, mode='train'):\n",
        "        \"\"\"Batch normalization.\"\"\"\n",
        "        with tf.variable_scope(name):\n",
        "            params_shape = [x.get_shape()[-1]]\n",
        "\n",
        "            beta = tf.get_variable(\n",
        "                'beta', params_shape, tf.float32,\n",
        "                initializer=tf.constant_initializer(0.0, tf.float32))\n",
        "            gamma = tf.get_variable(\n",
        "                'gamma', params_shape, tf.float32,\n",
        "                initializer=tf.constant_initializer(1.0, tf.float32))\n",
        "\n",
        "            if mode == 'train':\n",
        "                mean, variance = tf.nn.moments(x, [0, 1, 2], name='moments')\n",
        "\n",
        "                moving_mean = tf.get_variable(\n",
        "                    'moving_mean', params_shape, tf.float32,\n",
        "                    initializer=tf.constant_initializer(0.0, tf.float32),\n",
        "                    trainable=False)\n",
        "                moving_variance = tf.get_variable(\n",
        "                    'moving_variance', params_shape, tf.float32,\n",
        "                    initializer=tf.constant_initializer(1.0, tf.float32),\n",
        "                    trainable=False)\n",
        "\n",
        "                self._extra_train_ops.append(moving_averages.assign_moving_average(\n",
        "                    moving_mean, mean, 0.9))\n",
        "                self._extra_train_ops.append(moving_averages.assign_moving_average(\n",
        "                    moving_variance, variance, 0.9))\n",
        "            else:\n",
        "                mean = tf.get_variable(\n",
        "                    'moving_mean', params_shape, tf.float32,\n",
        "                    initializer=tf.constant_initializer(0.0, tf.float32),\n",
        "                    trainable=False)\n",
        "                variance = tf.get_variable(\n",
        "                    'moving_variance', params_shape, tf.float32,\n",
        "                    initializer=tf.constant_initializer(1.0, tf.float32),\n",
        "                    trainable=False)\n",
        "                # tf.summary.histogram(mean.op.name, mean)\n",
        "                # tf.summary.histogram(variance.op.name, variance)\n",
        "            # elipson solía ser 1e-5. Quizás 0.001 resuelva el problema de NaN en una red más profunda.\n",
        "            y = tf.nn.batch_normalization(\n",
        "                x, mean, variance, beta, gamma, 0.001)\n",
        "            y.set_shape(x.get_shape())\n",
        "            return y\n",
        "\n",
        "#Función decay:\n",
        "#L2 Weight Decay Loss: Esta función calcula la pérdida de decaimiento de pesos L2. Recorre todas las variables entrenables y,\n",
        "#si el nombre de la operación contiene la cadena 'weights', se aplica una regularización L2 a esa variable. Calcula la norma L2 de las variables de pesos y las suma.\n",
        "#Salida: Retorna el resultado de multiplicar la tasa de decaimiento de pesos (weight_decay_rate) por la suma de las normas L2 de las variables de pesos seleccionadas.\n",
        "    def decay(self):\n",
        "        \"\"\"L2 weight decay loss.\"\"\"\n",
        "        costs = []\n",
        "        for var in tf.trainable_variables():\n",
        "            if var.op.name.find(r'weights') > 0:\n",
        "                costs.append(tf.nn.l2_loss(var))\n",
        "        return tf.multiply(self.weight_decay_rate, tf.add_n(costs))\n",
        "\n",
        "#Función get_vars: Esta función se encarga de obtener y clasificar las variables en diferentes listas para su posterior uso.\n",
        "#Identifica y guarda las variables relacionadas con alexnet que no están relacionadas con la palabra clave 'age'.\n",
        "#Guarda las variables que contienen la palabra clave 'age' en una lista separada.\n",
        "#Crea listas específicas para variables relacionadas con un discriminador (save_d_vars) y un generador (save_g_vars) mediante la identificación de sus nombres.\n",
        "#Finalmente, recoge las variables entrenables (tf.trainable_variables()) para los discriminadores (d_vars) y generadores (g_vars).\n",
        "\n",
        "\n",
        "    def get_vars(self):\n",
        "\n",
        "        t_vars = tf.global_variables()\n",
        "\n",
        "        alexnet_vars = [var for var in t_vars if 'alexnet' in var.name]\n",
        "        self.alexnet_vars = [var for var in alexnet_vars if 'age' not in var.name]\n",
        "        self.age_vars = [var for var in t_vars if 'age' in var.name]\n",
        "\n",
        "        self.save_d_vars = [var for var in t_vars if 'discriminator' in var.name]\n",
        "        self.save_g_vars = [var for var in t_vars if 'generator' in var.name]\n",
        "        for var in self.save_g_vars:\n",
        "            print(var.name)\n",
        "\n",
        "        t_vars = tf.trainable_variables()\n",
        "        self.d_vars = [var for var in t_vars if 'discriminator' in var.name]\n",
        "        self.g_vars = [var for var in t_vars if 'generator' in var.name]\n",
        "\n",
        "#Función save:  se utiliza para guardar el modelo en un directorio específico proporcionado como checkpoint_dir con un nombre de modelo dado por prefix.\n",
        "#Verifica si el directorio existe. Si no, lo crea.\n",
        "#Utiliza tf.train.Saver para guardar el modelo en el directorio con un nombre que incluye el prefijo y el número de paso (step).\n",
        "\n",
        "\n",
        "    def save(self, checkpoint_dir, step, prefix):\n",
        "        model_name = prefix + '.model'\n",
        "        if not os.path.exists(checkpoint_dir):\n",
        "            os.makedirs(checkpoint_dir)\n",
        "\n",
        "        self.saver.save(self.sess, os.path.join(checkpoint_dir, model_name), global_step=step)\n",
        "\n",
        "#Función load: se utiliza para cargar modelos desde un directorio específico proporcionado como checkpoint_dir.\n",
        "#Utiliza tf.train.get_checkpoint_state para obtener el estado del punto de control y luego intenta cargar el modelo correspondiente a través de tf.train.Saver.restore.\n",
        "#Puede cargar un modelo específico según el número de modelo (model_num) y el prefijo.\n",
        "\n",
        "    def load(self, checkpoint_dir, saver, prefix=None, model_num=None):\n",
        "        print(\" [*] Reading checkpoints...\")\n",
        "        print(checkpoint_dir)\n",
        "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
        "        if model_num and prefix:\n",
        "            ckpt_name = prefix + '.model-' + str(model_num)\n",
        "            saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
        "            return True\n",
        "        elif ckpt and ckpt.model_checkpoint_path:\n",
        "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
        "            saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "#Función load_model\n",
        "#Carga de Modelo: Esta función se utiliza para cargar un modelo específico proporcionando el nombre del modelo (model_name) a través de tf.train.Saver.restore.\n",
        "\n",
        "    def load_model(self, model_name):\n",
        "        print(\"load model\" + model_name)\n",
        "        self.saver.restore(self.sess, model_name)\n",
        "\n"
      ],
      "metadata": {
        "id": "iQUBFVrq6oKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRINCIPAL"
      ],
      "metadata": {
        "id": "hSYlxGmTUn3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prueba"
      ],
      "metadata": {
        "id": "wqBAn4MWIOeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import imageio\n",
        "import os"
      ],
      "metadata": {
        "id": "aVjLcEVs-YYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_images(images, size, image_path):\n",
        "    if images.ndim < 2 or images.ndim > 4:\n",
        "        raise ValueError(\"Image must be 2D (grayscale, RGB, or RGBA) or 3D (batch of 2D images).\")\n",
        "    # ..."
      ],
      "metadata": {
        "id": "sdXE0q2r-fEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of the 'images' variable.\n",
        "print(images.shape)\n",
        "\n",
        "# Check if the 'images' variable is a batch of images.\n",
        "if len(images.shape) == 3:\n",
        "    print(\"The 'images' variable is a batch of images.\")\n",
        "else:\n",
        "    print(\"The 'images' variable is a single image.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "BW0b49cJ-iX1",
        "outputId": "d5003fab-5835-4844-9b2a-50ef0953f3e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-741e79c99749>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print the shape of the 'images' variable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Check if the 'images' variable is a batch of images.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#def save_images(images, size, image_path):\n",
        "  #  if images.ndim == 2:\n",
        "        # Expand the dimensions of the image to create a batch.\n",
        "   #     images = np.expand_dims(images, axis=0)\n",
        "    # ..."
      ],
      "metadata": {
        "id": "ZU6Xt3VJ-pNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import os\n",
        "#os.environ['CUDA_DEVICES_ORDER'] = \"PCI_BUS_ID\"\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import sys\n",
        "\n",
        "#modifica temporalmente la funcionalidad de 'sys.exit' para evitar que el programa se cierre cuando se llama a esta función. - 'sys.argv = sys.argv[:1]'\n",
        "sys.argv = sys.argv[:1]\n",
        "old_sysexit = sys.exit\n",
        "try:\n",
        "    sys.exit = lambda *args: None\n",
        "\n",
        "finally:\n",
        "    sys.exit = old_sysexit\n"
      ],
      "metadata": {
        "id": "sOvmNHu7dUyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import tensorflow.compat.v1 as tf"
      ],
      "metadata": {
        "id": "GhApVyEVgTQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "flags = tf.app.flags\n",
        "\n",
        "#\"learning_rate\": Define la tasa de aprendizaje para el entrenamiento del modelo. Su valor predeterminado es 0.001.\n",
        "flags.DEFINE_float(\"learning_rate\", 0.001, \"Learning rate\")\n",
        "\n",
        "#\"batch_size\": Establece el tamaño del lote de imágenes utilizado durante el entrenamiento. Su valor predeterminado es 32.\n",
        "flags.DEFINE_integer(\"batch_size\", 32, \"The size of batch images\")\n",
        "\n",
        "#\"image_size\": Define el tamaño de la imagen generada. Su valor predeterminado es 128.\n",
        "flags.DEFINE_integer(\"image_size\", 128, \"the size of the generated image\")\n",
        "\n",
        "#\"noise_dim\": Representa la longitud del vector de ruido utilizado en alguna parte del modelo. Su valor predeterminado es 256.\n",
        "flags.DEFINE_integer(\"noise_dim\", 256, \"the length of the noise vector\")\n",
        "\n",
        "#\"feature_size\": Indica el tamaño de la imagen después de aplicar una convolución con un stride de 2. Su valor predeterminado es 128.\n",
        "flags.DEFINE_integer(\"feature_size\", 128, \"image size after stride 2 conv\")\n",
        "\n",
        "#\"age_groups\": Define el número de grupos de edades diferentes. Su valor predeterminado es 5\n",
        "flags.DEFINE_integer(\"age_groups\", 5, \"the number of different age groups\")\n",
        "\n",
        "#\"model_index\": Representa el índice del modelo entrenado. Inicialmente se establece en None.\n",
        "flags.DEFINE_integer('model_index', None, 'the index of trained model')\n",
        "\n",
        "\n",
        "#\"gan_loss_weight\", \"fea_loss_weight\", \"age_loss_weight\", \"tv_loss_weight\": Son pesos asociados con diferentes tipos de pérdidas Inicialmente se establecen en None\n",
        "\n",
        "flags.DEFINE_float(\"gan_loss_weight\", None, \"gan_loss_weight\")\n",
        "\n",
        "flags.DEFINE_float(\"fea_loss_weight\", None, \"fea_loss_weight\")\n",
        "\n",
        "flags.DEFINE_float(\"age_loss_weight\", None, \"age_loss_weight\")\n",
        "\n",
        "flags.DEFINE_float(\"tv_loss_weight\", None, \"face_loss_weight\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWFRbeQISxhq",
        "outputId": "26ff4fe6-1fd2-4df4-87ea-d72f4004b360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<absl.flags._flagvalues.FlagHolder at 0x7fc85ccb9de0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#FLAGS = flags.FLAGS: crea un objeto FLAGS que se utiliza para acceder a los indicadores definidos en este código.\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "#\"pretrained_checkpoint_dir\": Representa el directorio donde se encuentra un modelo pre-entrenado.\n",
        "flags.DEFINE_string(\"pretrained_checkpoint_dir\", '/content/drive/MyDrive/checkpoints/0_conv5_lsgan_transfer_g75_0.5f-4_a30/',\n",
        "                    \"Directory name: pre-trained model\")\n",
        "\n",
        "#\"custom_checkpoint_dir\": Indica el directorio donde se guardarán los puntos de control durante el entrenamiento desde cero (sin un modelo pre-entrenado).\n",
        "#Aquí se almacenarán los checkpoints del modelo durante el proceso de entrenamiento.\n",
        "flags.DEFINE_string(\"custom_checkpoint_dir\", '/content/drive/MyDrive/checkpoints/conv5_lsgan_transfer',\n",
        "                    \"Directory name to save the checkpoints for training from scratch\")\n",
        "\n",
        "#\"custom_model_number\": Especifica el número de modelo personalizado. En este caso, el valor es '399999'\n",
        "flags.DEFINE_string(\"custom_model_number\", '399999',\n",
        "                    \"Directory name to save the sample images\")\n",
        "\n",
        "#\"save_dir\": Indica el directorio donde se guardarán imágenes de muestra generadas por el modelo durante o después del entrenamiento.\n",
        "flags.DEFINE_string(\"save_dir\", '/content/drive/MyDrive/prueba_sal',\n",
        "                    \"Directory name to save the sample images\")\n",
        "\n",
        "#\"root_folder\": Representa la carpeta raíz que contiene las imágenes utilizadas para el entrenamiento del modelo.\n",
        "flags.DEFINE_string(\"root_folder\", '/content/drive/MyDrive/Pruebas-Tesis/TrainingSet_CACD2000.zip/', \"folder that contains images\")\n",
        "\n",
        "\n",
        "#\"test_data_dir\" y \"train_data_dir\": Son directorios que indican la ubicación de las imágenes de prueba y entrenamiento\n",
        "flags.DEFINE_string(\"test_data_dir\", '/content/drive/MyDrive/images/your_test_images', \"test images\")\n",
        "\n",
        "flags.DEFINE_string(\"train_data_dir\", '/content/drive/MyDrive/images/train', \"train images\")\n",
        "\n"
      ],
      "metadata": {
        "id": "sHwa9PpK7F8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f58e0c3-5c8f-4def-c0a9-db137cbb1109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<absl.flags._flagvalues.FlagHolder at 0x7fc85ccba4a0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tf.ConfigProto()  configurar el comportamiento de ejecución de TensorFlow.Se utiliza para definir diversas configuraciones que afectan al entorno de ejecución, como el uso de recursos como CPU, GPU,\n",
        "config = tf.ConfigProto()\n",
        "\n",
        "#config.gpu_options.allow_growth = True: Esta línea configura la opción de asignación de memoria de la GPU para permitir el crecimiento dinámico de la memoria.\n",
        "#Cuando se establece en True\n",
        "config.gpu_options.allow_growth = True"
      ],
      "metadata": {
        "id": "3NcuG2eXdVu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#batch_size: Define el tamaño de lote de imágenes que se utilizarán durante cada iteración del entrenamiento o la validación.\n",
        "#height y width: Representan la altura y el ancho de las imágenes que se esperan como entrada para el modelo\n",
        "#z_dim: Define la dimensión del vector de ruido, que podría utilizarse como entrada para una red generativa\n",
        "#scale_size: Especifica el tamaño al que se redimensionarán las imágenes.\n",
        "#shuffle: Cuando se establece en False, desactiva la mezcla aleatoria de los datos en cada época durante el entrenamiento o la validación.\n",
        "#root_folder: Representa la carpeta raíz que contiene las imágenes utilizadas para el entrenamiento o la validación\n",
        "#mode: Define si se está configurando un generador de datos para el modo de entrenamiento ('train') o de prueba ('test').\n",
        "\n",
        "generator = ImageDataGenerator(batch_size=FLAGS.batch_size, height=FLAGS.feature_size, width=FLAGS.feature_size,\n",
        "                               z_dim=FLAGS.noise_dim, scale_size=(FLAGS.image_size, FLAGS.image_size),\n",
        "                               shuffle=False,root_folder= FLAGS.root_folder, mode='train')\n",
        "\n",
        "val_generator = ImageDataGenerator(batch_size=FLAGS.batch_size, height=FLAGS.feature_size, width=FLAGS.feature_size,\n",
        "                                   z_dim=FLAGS.noise_dim, scale_size=(FLAGS.image_size, FLAGS.image_size),\n",
        "                                   shuffle=False, root_folder= FLAGS.root_folder, mode='test')\n"
      ],
      "metadata": {
        "id": "y4QkavKa3ERW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imageio import imsave\n",
        "def my_test():\n",
        "  #Se crea un nuevo grafo de TensorFlow con tf.Graph().as_default().\n",
        "    with tf.Graph().as_default():\n",
        "      #Se inicia una sesión de TensorFlow (tf.Session) con la configuración definida previamente en config\n",
        "        sess = tf.Session(config=config)\n",
        "        #se instancia un objeto FaceAging que representa el modelo\n",
        "        #sess: La sesión de TensorFlow creada.\n",
        "        #lr: La tasa de aprendizaje tomada de FLAGS.learning_rate.\n",
        "        #keep_prob: Una tasa de retención (mantenimiento) para la técnica de dropout, establecida en 1.0, lo que significa que no se está aplicando dropout.\n",
        "        #model_num: El número de modelo extraído de FLAGS.model_index.\n",
        "        #batch_size, age_loss_weight, gan_loss_weight, fea_loss_weight, tv_loss_weight: configuraciones y pesos relacionados con el modelo tomados de los flags\n",
        "\n",
        "        model = FaceAging(sess=sess, lr=FLAGS.learning_rate, keep_prob=1., model_num=FLAGS.model_index, batch_size=FLAGS.batch_size,\n",
        "                        age_loss_weight=FLAGS.age_loss_weight, gan_loss_weight=FLAGS.gan_loss_weight,\n",
        "                        fea_loss_weight=FLAGS.fea_loss_weight, tv_loss_weight=FLAGS.tv_loss_weight)\n",
        "\n",
        "        model.imgs = tf.placeholder(tf.float32, [FLAGS.batch_size, FLAGS.image_size, FLAGS.image_size, 3])\n",
        "        model.true_label_features_128 = tf.placeholder(tf.float32, [FLAGS.batch_size, 128, 128, FLAGS.age_groups])\n",
        "\n",
        "        model.ge_samples = model.generate_images(model.imgs, model.true_label_features_128, stable_bn=False, mode='train')\n",
        "\n",
        "        model.get_vars()\n",
        "\n",
        "        # Crea un ahorrador.\n",
        "        #Se crea un objeto tf.train.Saver para guardar los parámetros entrenables del modelo (model.save_g_vars).\n",
        "        model.saver = tf.train.Saver(model.save_g_vars)\n",
        "\n",
        "        # Comience a ejecutar operaciones en Graph.\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        #if model.load(FLAGS.checkpoint_dir, model.saver, 'acgan', 399999):\n",
        "        if model.load(FLAGS.custom_checkpoint_dir, model.saver, 'acgan', FLAGS.custom_model_number):\n",
        "            print(\" [*] Load SUCCESS\")\n",
        "        else:\n",
        "            print(\" [!] Load failed...\")\n",
        "\n",
        "        print(\"{} Start testing...\")\n",
        "        #Se verifica si el directorio para guardar las imágenes de prueba (FLAGS.save_dir)\n",
        "\n",
        "        if not os.path.exists(FLAGS.save_dir):\n",
        "            os.makedirs(FLAGS.save_dir)\n",
        "\n",
        "        # stable_bn(model, sess, 10000)\n",
        "        # generate_images(model, sess)\n",
        "        #Se llama a la función generate_images_from_folder para generar imágenes a partir de datos ubicados en carpetas específicas (FLAGS.test_data_dir y FLAGS.train_data_dir).\n",
        "        generate_images_from_folder(model, sess, FLAGS.test_data_dir, FLAGS.train_data_dir)\n",
        "\n",
        "\n",
        "#generator.n_classes = len(generator.labels), no guardo la imagen\n",
        "#Función generate_images_from_folder: Generar imágenes a partir de carpetas de datos.\n",
        "def generate_images_from_folder(model, sess, test_data_dir=None, train_data_dir=None):\n",
        "    if test_data_dir:\n",
        "        source, paths = val_generator.load_imgs(test_data_dir, 128)\n",
        "    else:\n",
        "        source, paths = val_generator.next_source_imgs(0, 128, batch_size=256)\n",
        "\n",
        "    if train_data_dir:\n",
        "        train_imgs, _ = generator.load_imgs(train_data_dir, 128)\n",
        "    else:\n",
        "        train_imgs, _ = generator.next_source_imgs(0, 128, batch_size=FLAGS.batch_size-1)\n",
        "\n",
        "    assert train_imgs.shape[0] == (FLAGS.batch_size-1)\n",
        "\n",
        "#Itera sobre las imágenes de prueba y las combina con las imágenes de entrenamiento para generar diferentes versiones de las imágenes de prueba utilizando el modelo.\n",
        "\n",
        "    for i in range(len(paths)):\n",
        "        print (i)\n",
        "        temp = np.reshape(source[i], (1, 128, 128, 3))\n",
        "        #cv2.imwrite(path, img[:, :, [2, 1, 0]])\n",
        "        save_source(temp, [1, 1], os.path.join(FLAGS.save_dir, paths[i]))\n",
        "        images = np.concatenate((temp, train_imgs), axis=0)\n",
        "        for j in range(1, generator.n_classes):\n",
        "            true_label_fea = generator.label_features_128[j]\n",
        "            #print(\"pasa?\")\n",
        "            dict = {\n",
        "                    model.imgs: images,\n",
        "                    model.true_label_features_128: true_label_fea,\n",
        "                    }\n",
        "            samples = sess.run(model.ge_samples, feed_dict=dict)\n",
        "            image = np.reshape(samples[0, :, :, :], (1, 128, 128, 3))\n",
        "            # generator.save_batch(samples, paths, FLAGS.save_dir, index=j, if_target=True)\n",
        "            # Guarda estas imágenes generadas en FLAGS.save_dir.\n",
        "            #save_images(image[0], [1, 1], os.path.join(FLAGS.save_dir, paths[i] + '_' + str(j) + '.jpg'))\n",
        "            save_images(image, [1, 1], os.path.join(FLAGS.save_dir, paths[i] + '_' + str(j) + '.jpg'))\n",
        "\n",
        "\n",
        "#Función generate_images: Generar imágenes utilizando un modelo y datos de validación.\n",
        "#Carga un conjunto de imágenes de validación (source) desde el generador (val_generator).\n",
        "#Utiliza el modelo para generar imágenes modificadas a partir de estas imágenes de validación y las guarda en FLAGS.save_dir.\n",
        "\n",
        "def generate_images(model, sess):\n",
        "    source, paths = val_generator.next_source_imgs(0, 128, batch_size=FLAGS.batch_size)\n",
        "    time1 = time.time()\n",
        "    for j in range(1, generator.n_classes):\n",
        "        true_label_fea = generator.label_features_128[j]\n",
        "        dict = {\n",
        "                model.imgs: source,\n",
        "                model.true_label_features_128: true_label_fea,\n",
        "                }\n",
        "        samples = sess.run(model.ge_samples, feed_dict=dict)\n",
        "        # image = np.reshape(samples[0, :, :, :], (1, 128, 128, 3))\n",
        "        save_images(samples, [1, 1], os.path.join(FLAGS.save_dir, paths[0] + '_' + str(j) + '.jpg'))\n",
        "\n",
        "    time2 = time.time() - time1\n",
        "    print (time2)\n",
        "\n",
        "#Función stable_bn: Estabilizar la normalización por lotes durante el entrenamiento.\n",
        "#Genera un conjunto de imágenes de entrenamiento (train_imgs) utilizando el generador.\n",
        "#Utiliza el modelo y el conjunto de entrenamiento para realizar operaciones de optimización para estabilizar la normalización por lotes (model.optim).\n",
        "\n",
        "def stable_bn(model, sess, num_iter):\n",
        "    for iter in range(num_iter):\n",
        "        print (iter)\n",
        "        train_imgs, _ = generator.next_source_imgs(0, 128, batch_size=FLAGS.batch_size)\n",
        "        for j in range(1, generator.n_classes):\n",
        "            true_label_fea = generator.label_features_128[j]\n",
        "            dict = {\n",
        "                model.imgs: train_imgs,\n",
        "                model.true_label_features_128: true_label_fea,\n",
        "            }\n",
        "            sess.run([model.ge_samples, model.optim], feed_dict=dict)\n",
        "\n",
        "    checkpoint_path = os.path.join(FLAGS.checkpoint_dir)\n",
        "    model.save(checkpoint_path, 1000000, 'acgan')\n",
        "\n"
      ],
      "metadata": {
        "id": "GDOu3IUVL5rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#la función main() llama a otra función llamada my_test()\n",
        "def main(argv=None):\n",
        "    my_test()"
      ],
      "metadata": {
        "id": "duG1CXAj1R2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verifica si es el archivo principal y luego utiliza tf.app.run()\n",
        "if __name__ == '__main__':\n",
        "    tf.app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8NZV5wri1Ve1",
        "outputId": "d3f1539f-d325-4b5b-ffd7-4e9741a84926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Tensor.get_shape of <tf.Tensor 'generator/conv4/Reshape:0' shape=(32, 128, 128, 3) dtype=float32>>\n",
            "generator/conv1/weights:0\n",
            "generator/conv1/biases:0\n",
            "generator/bn1/beta:0\n",
            "generator/bn1/gamma:0\n",
            "generator/bn1/moving_mean:0\n",
            "generator/bn1/moving_variance:0\n",
            "generator/bn1/generator/bn1/moving_mean/biased:0\n",
            "generator/bn1/generator/bn1/moving_mean/local_step:0\n",
            "generator/bn1/generator/bn1/moving_variance/biased:0\n",
            "generator/bn1/generator/bn1/moving_variance/local_step:0\n",
            "generator/conv2/weights:0\n",
            "generator/conv2/biases:0\n",
            "generator/bn2/beta:0\n",
            "generator/bn2/gamma:0\n",
            "generator/bn2/moving_mean:0\n",
            "generator/bn2/moving_variance:0\n",
            "generator/bn2/generator/bn2/moving_mean/biased:0\n",
            "generator/bn2/generator/bn2/moving_mean/local_step:0\n",
            "generator/bn2/generator/bn2/moving_variance/biased:0\n",
            "generator/bn2/generator/bn2/moving_variance/local_step:0\n",
            "generator/conv3/weights:0\n",
            "generator/conv3/biases:0\n",
            "generator/bn3/beta:0\n",
            "generator/bn3/gamma:0\n",
            "generator/bn3/moving_mean:0\n",
            "generator/bn3/moving_variance:0\n",
            "generator/bn3/generator/bn3/moving_mean/biased:0\n",
            "generator/bn3/generator/bn3/moving_mean/local_step:0\n",
            "generator/bn3/generator/bn3/moving_variance/biased:0\n",
            "generator/bn3/generator/bn3/moving_variance/local_step:0\n",
            "generator/unit_0/sub1/conv1/weights:0\n",
            "generator/unit_0/sub1/conv1/biases:0\n",
            "generator/unit_0/sub1/bn1/beta:0\n",
            "generator/unit_0/sub1/bn1/gamma:0\n",
            "generator/unit_0/sub1/bn1/moving_mean:0\n",
            "generator/unit_0/sub1/bn1/moving_variance:0\n",
            "generator/unit_0/sub1/bn1/generator/unit_0/sub1/bn1/moving_mean/biased:0\n",
            "generator/unit_0/sub1/bn1/generator/unit_0/sub1/bn1/moving_mean/local_step:0\n",
            "generator/unit_0/sub1/bn1/generator/unit_0/sub1/bn1/moving_variance/biased:0\n",
            "generator/unit_0/sub1/bn1/generator/unit_0/sub1/bn1/moving_variance/local_step:0\n",
            "generator/unit_0/sub2/conv2/weights:0\n",
            "generator/unit_0/sub2/conv2/biases:0\n",
            "generator/unit_0/sub2/bn2/beta:0\n",
            "generator/unit_0/sub2/bn2/gamma:0\n",
            "generator/unit_0/sub2/bn2/moving_mean:0\n",
            "generator/unit_0/sub2/bn2/moving_variance:0\n",
            "generator/unit_0/sub2/bn2/generator/unit_0/sub2/bn2/moving_mean/biased:0\n",
            "generator/unit_0/sub2/bn2/generator/unit_0/sub2/bn2/moving_mean/local_step:0\n",
            "generator/unit_0/sub2/bn2/generator/unit_0/sub2/bn2/moving_variance/biased:0\n",
            "generator/unit_0/sub2/bn2/generator/unit_0/sub2/bn2/moving_variance/local_step:0\n",
            "generator/unit_1/sub1/conv1/weights:0\n",
            "generator/unit_1/sub1/conv1/biases:0\n",
            "generator/unit_1/sub1/bn1/beta:0\n",
            "generator/unit_1/sub1/bn1/gamma:0\n",
            "generator/unit_1/sub1/bn1/moving_mean:0\n",
            "generator/unit_1/sub1/bn1/moving_variance:0\n",
            "generator/unit_1/sub1/bn1/generator/unit_1/sub1/bn1/moving_mean/biased:0\n",
            "generator/unit_1/sub1/bn1/generator/unit_1/sub1/bn1/moving_mean/local_step:0\n",
            "generator/unit_1/sub1/bn1/generator/unit_1/sub1/bn1/moving_variance/biased:0\n",
            "generator/unit_1/sub1/bn1/generator/unit_1/sub1/bn1/moving_variance/local_step:0\n",
            "generator/unit_1/sub2/conv2/weights:0\n",
            "generator/unit_1/sub2/conv2/biases:0\n",
            "generator/unit_1/sub2/bn2/beta:0\n",
            "generator/unit_1/sub2/bn2/gamma:0\n",
            "generator/unit_1/sub2/bn2/moving_mean:0\n",
            "generator/unit_1/sub2/bn2/moving_variance:0\n",
            "generator/unit_1/sub2/bn2/generator/unit_1/sub2/bn2/moving_mean/biased:0\n",
            "generator/unit_1/sub2/bn2/generator/unit_1/sub2/bn2/moving_mean/local_step:0\n",
            "generator/unit_1/sub2/bn2/generator/unit_1/sub2/bn2/moving_variance/biased:0\n",
            "generator/unit_1/sub2/bn2/generator/unit_1/sub2/bn2/moving_variance/local_step:0\n",
            "generator/unit_2/sub1/conv1/weights:0\n",
            "generator/unit_2/sub1/conv1/biases:0\n",
            "generator/unit_2/sub1/bn1/beta:0\n",
            "generator/unit_2/sub1/bn1/gamma:0\n",
            "generator/unit_2/sub1/bn1/moving_mean:0\n",
            "generator/unit_2/sub1/bn1/moving_variance:0\n",
            "generator/unit_2/sub1/bn1/generator/unit_2/sub1/bn1/moving_mean/biased:0\n",
            "generator/unit_2/sub1/bn1/generator/unit_2/sub1/bn1/moving_mean/local_step:0\n",
            "generator/unit_2/sub1/bn1/generator/unit_2/sub1/bn1/moving_variance/biased:0\n",
            "generator/unit_2/sub1/bn1/generator/unit_2/sub1/bn1/moving_variance/local_step:0\n",
            "generator/unit_2/sub2/conv2/weights:0\n",
            "generator/unit_2/sub2/conv2/biases:0\n",
            "generator/unit_2/sub2/bn2/beta:0\n",
            "generator/unit_2/sub2/bn2/gamma:0\n",
            "generator/unit_2/sub2/bn2/moving_mean:0\n",
            "generator/unit_2/sub2/bn2/moving_variance:0\n",
            "generator/unit_2/sub2/bn2/generator/unit_2/sub2/bn2/moving_mean/biased:0\n",
            "generator/unit_2/sub2/bn2/generator/unit_2/sub2/bn2/moving_mean/local_step:0\n",
            "generator/unit_2/sub2/bn2/generator/unit_2/sub2/bn2/moving_variance/biased:0\n",
            "generator/unit_2/sub2/bn2/generator/unit_2/sub2/bn2/moving_variance/local_step:0\n",
            "generator/unit_3/sub1/conv1/weights:0\n",
            "generator/unit_3/sub1/conv1/biases:0\n",
            "generator/unit_3/sub1/bn1/beta:0\n",
            "generator/unit_3/sub1/bn1/gamma:0\n",
            "generator/unit_3/sub1/bn1/moving_mean:0\n",
            "generator/unit_3/sub1/bn1/moving_variance:0\n",
            "generator/unit_3/sub1/bn1/generator/unit_3/sub1/bn1/moving_mean/biased:0\n",
            "generator/unit_3/sub1/bn1/generator/unit_3/sub1/bn1/moving_mean/local_step:0\n",
            "generator/unit_3/sub1/bn1/generator/unit_3/sub1/bn1/moving_variance/biased:0\n",
            "generator/unit_3/sub1/bn1/generator/unit_3/sub1/bn1/moving_variance/local_step:0\n",
            "generator/unit_3/sub2/conv2/weights:0\n",
            "generator/unit_3/sub2/conv2/biases:0\n",
            "generator/unit_3/sub2/bn2/beta:0\n",
            "generator/unit_3/sub2/bn2/gamma:0\n",
            "generator/unit_3/sub2/bn2/moving_mean:0\n",
            "generator/unit_3/sub2/bn2/moving_variance:0\n",
            "generator/unit_3/sub2/bn2/generator/unit_3/sub2/bn2/moving_mean/biased:0\n",
            "generator/unit_3/sub2/bn2/generator/unit_3/sub2/bn2/moving_mean/local_step:0\n",
            "generator/unit_3/sub2/bn2/generator/unit_3/sub2/bn2/moving_variance/biased:0\n",
            "generator/unit_3/sub2/bn2/generator/unit_3/sub2/bn2/moving_variance/local_step:0\n",
            "generator/unit_4/sub1/conv1/weights:0\n",
            "generator/unit_4/sub1/conv1/biases:0\n",
            "generator/unit_4/sub1/bn1/beta:0\n",
            "generator/unit_4/sub1/bn1/gamma:0\n",
            "generator/unit_4/sub1/bn1/moving_mean:0\n",
            "generator/unit_4/sub1/bn1/moving_variance:0\n",
            "generator/unit_4/sub1/bn1/generator/unit_4/sub1/bn1/moving_mean/biased:0\n",
            "generator/unit_4/sub1/bn1/generator/unit_4/sub1/bn1/moving_mean/local_step:0\n",
            "generator/unit_4/sub1/bn1/generator/unit_4/sub1/bn1/moving_variance/biased:0\n",
            "generator/unit_4/sub1/bn1/generator/unit_4/sub1/bn1/moving_variance/local_step:0\n",
            "generator/unit_4/sub2/conv2/weights:0\n",
            "generator/unit_4/sub2/conv2/biases:0\n",
            "generator/unit_4/sub2/bn2/beta:0\n",
            "generator/unit_4/sub2/bn2/gamma:0\n",
            "generator/unit_4/sub2/bn2/moving_mean:0\n",
            "generator/unit_4/sub2/bn2/moving_variance:0\n",
            "generator/unit_4/sub2/bn2/generator/unit_4/sub2/bn2/moving_mean/biased:0\n",
            "generator/unit_4/sub2/bn2/generator/unit_4/sub2/bn2/moving_mean/local_step:0\n",
            "generator/unit_4/sub2/bn2/generator/unit_4/sub2/bn2/moving_variance/biased:0\n",
            "generator/unit_4/sub2/bn2/generator/unit_4/sub2/bn2/moving_variance/local_step:0\n",
            "generator/unit_5/sub1/conv1/weights:0\n",
            "generator/unit_5/sub1/conv1/biases:0\n",
            "generator/unit_5/sub1/bn1/beta:0\n",
            "generator/unit_5/sub1/bn1/gamma:0\n",
            "generator/unit_5/sub1/bn1/moving_mean:0\n",
            "generator/unit_5/sub1/bn1/moving_variance:0\n",
            "generator/unit_5/sub1/bn1/generator/unit_5/sub1/bn1/moving_mean/biased:0\n",
            "generator/unit_5/sub1/bn1/generator/unit_5/sub1/bn1/moving_mean/local_step:0\n",
            "generator/unit_5/sub1/bn1/generator/unit_5/sub1/bn1/moving_variance/biased:0\n",
            "generator/unit_5/sub1/bn1/generator/unit_5/sub1/bn1/moving_variance/local_step:0\n",
            "generator/unit_5/sub2/conv2/weights:0\n",
            "generator/unit_5/sub2/conv2/biases:0\n",
            "generator/unit_5/sub2/bn2/beta:0\n",
            "generator/unit_5/sub2/bn2/gamma:0\n",
            "generator/unit_5/sub2/bn2/moving_mean:0\n",
            "generator/unit_5/sub2/bn2/moving_variance:0\n",
            "generator/unit_5/sub2/bn2/generator/unit_5/sub2/bn2/moving_mean/biased:0\n",
            "generator/unit_5/sub2/bn2/generator/unit_5/sub2/bn2/moving_mean/local_step:0\n",
            "generator/unit_5/sub2/bn2/generator/unit_5/sub2/bn2/moving_variance/biased:0\n",
            "generator/unit_5/sub2/bn2/generator/unit_5/sub2/bn2/moving_variance/local_step:0\n",
            "generator/deconv1/weights:0\n",
            "generator/deconv1/biases:0\n",
            "generator/bn4/beta:0\n",
            "generator/bn4/gamma:0\n",
            "generator/bn4/moving_mean:0\n",
            "generator/bn4/moving_variance:0\n",
            "generator/bn4/generator/bn4/moving_mean/biased:0\n",
            "generator/bn4/generator/bn4/moving_mean/local_step:0\n",
            "generator/bn4/generator/bn4/moving_variance/biased:0\n",
            "generator/bn4/generator/bn4/moving_variance/local_step:0\n",
            "generator/deconv2/weights:0\n",
            "generator/deconv2/biases:0\n",
            "generator/bn5/beta:0\n",
            "generator/bn5/gamma:0\n",
            "generator/bn5/moving_mean:0\n",
            "generator/bn5/moving_variance:0\n",
            "generator/bn5/generator/bn5/moving_mean/biased:0\n",
            "generator/bn5/generator/bn5/moving_mean/local_step:0\n",
            "generator/bn5/generator/bn5/moving_variance/biased:0\n",
            "generator/bn5/generator/bn5/moving_variance/local_step:0\n",
            "generator/conv4/weights:0\n",
            "generator/conv4/biases:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "I0126 04:54:24.042539 140501368553472 saver.py:1413] Restoring parameters from /content/drive/MyDrive/checkpoints/conv5_lsgan_transfer/acgan.model-399999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [*] Reading checkpoints...\n",
            "/content/drive/MyDrive/checkpoints/conv5_lsgan_transfer\n",
            " [*] Load SUCCESS\n",
            "{} Start testing...\n",
            "0\n",
            "(1, 128, 128, 3)\n",
            "(1, 128, 128, 3)\n",
            "(1, 128, 128, 3)\n",
            "(1, 128, 128, 3)\n",
            "(1, 128, 128, 3)\n",
            "1\n",
            "(1, 128, 128, 3)\n",
            "(1, 128, 128, 3)\n",
            "(1, 128, 128, 3)\n",
            "(1, 128, 128, 3)\n",
            "(1, 128, 128, 3)\n",
            "2\n",
            "(1, 128, 128, 3)\n",
            "(1, 128, 128, 3)\n",
            "(1, 128, 128, 3)\n",
            "(1, 128, 128, 3)\n",
            "(1, 128, 128, 3)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "juQey9c-Ny7D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}